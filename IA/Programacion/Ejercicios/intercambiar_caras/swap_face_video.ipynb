{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "from mediapipe import solutions\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH = \"images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks_on_image(rgb_image, detection_result):\n",
    "    face_landmarks_list = detection_result.face_landmarks\n",
    "    annotated_image = np.copy(rgb_image)\n",
    "\n",
    "    # Loop through the detected faces to visualize.\n",
    "    for idx in range(len(face_landmarks_list)):\n",
    "        face_landmarks = face_landmarks_list[idx]\n",
    "\n",
    "        # Draw the face landmarks.\n",
    "        face_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "        face_landmarks_proto.landmark.extend([\n",
    "          landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in face_landmarks\n",
    "        ])\n",
    "\t\t# triangles\n",
    "        solutions.drawing_utils.draw_landmarks(\n",
    "            image=annotated_image,\n",
    "            landmark_list=face_landmarks_proto,\n",
    "            connections=mp.solutions.face_mesh.FACEMESH_TESSELATION,\n",
    "            landmark_drawing_spec=None,\n",
    "            connection_drawing_spec=mp.solutions.drawing_styles\n",
    "            .get_default_face_mesh_tesselation_style())\n",
    "        # eye - eyebrows\n",
    "        solutions.drawing_utils.draw_landmarks(\n",
    "            image=annotated_image,\n",
    "            landmark_list=face_landmarks_proto,\n",
    "            connections=mp.solutions.face_mesh.FACEMESH_CONTOURS,\n",
    "            landmark_drawing_spec=None,\n",
    "            connection_drawing_spec=mp.solutions.drawing_styles\n",
    "            .get_default_face_mesh_contours_style())\n",
    "        # iris\n",
    "        solutions.drawing_utils.draw_landmarks(\n",
    "            image=annotated_image,\n",
    "            landmark_list=face_landmarks_proto,\n",
    "            connections=mp.solutions.face_mesh.FACEMESH_IRISES,\n",
    "            landmark_drawing_spec=None,\n",
    "            connection_drawing_spec=mp.solutions.drawing_styles\n",
    "            .get_default_face_mesh_iris_connections_style())\n",
    "  \n",
    "    return annotated_image\n",
    "\n",
    "def plot_face_blendshapes_bar_graph(face_blendshapes):\n",
    "    # Extract the face blendshapes category names and scores.\n",
    "    face_blendshapes_names = [face_blendshapes_category.category_name for face_blendshapes_category in face_blendshapes]\n",
    "    face_blendshapes_scores = [face_blendshapes_category.score for face_blendshapes_category in face_blendshapes]\n",
    "    # The blendshapes are ordered in decreasing score value.\n",
    "    face_blendshapes_ranks = range(len(face_blendshapes_names))\n",
    "  \n",
    "    _, ax = plt.subplots(figsize=(12, 12))\n",
    "    bar = ax.barh(face_blendshapes_ranks, face_blendshapes_scores, label=[str(x) for x in face_blendshapes_ranks])\n",
    "    ax.set_yticks(face_blendshapes_ranks, face_blendshapes_names)\n",
    "    ax.invert_yaxis()\n",
    "  \n",
    "    # Label each bar with values\n",
    "    for score, patch in zip(face_blendshapes_scores, bar.patches):\n",
    "        plt.text(patch.get_x() + patch.get_width(), patch.get_y(), f\"{score:.4f}\", va=\"top\")\n",
    "  \n",
    "    ax.set_xlabel('Score')\n",
    "    ax.set_title(\"Face Blendshapes\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def get_landmark_points(face_landmarks, img):\n",
    "    landmarks_points = []\n",
    "    for landmark in face_landmarks:\n",
    "        landmarks_points.append((landmark.x*img.shape[1],\n",
    "                                 landmark.y*img.shape[0]))\n",
    "    \n",
    "    return landmarks_points\n",
    "\n",
    "def get_index_triangles(points, triangles):\n",
    "    indexes_triangles = []\n",
    "    for t in triangles:\n",
    "        pt1 = (t[0], t[1])\n",
    "        pt2 = (t[2], t[3])\n",
    "        pt3 = (t[4], t[5])\n",
    "\n",
    "        index_pt1 = np.where((points == pt1).all(axis=1))[0][0]\n",
    "        index_pt2 = np.where((points == pt2).all(axis=1))[0][0]\n",
    "        index_pt3 = np.where((points == pt3).all(axis=1))[0][0]\n",
    "\n",
    "        indexes_triangles.append([index_pt1, index_pt2, index_pt3])\n",
    "    \n",
    "    return indexes_triangles\n",
    "\n",
    "def triangulation(landmarks_points, triangle_index):\n",
    "    tr_pt1 = landmarks_points[triangle_index[0]]\n",
    "    tr_pt2 = landmarks_points[triangle_index[1]]\n",
    "    tr_pt3 = landmarks_points[triangle_index[2]]\n",
    "    triangle = np.array([tr_pt1, tr_pt2, tr_pt3], np.int32)\n",
    "    rect1 = cv.boundingRect(triangle)\n",
    "    (x, y, w, h) = rect1\n",
    "    cropped_tr_mask = np.zeros((h, w), np.uint8)\n",
    "\n",
    "    points = np.array([[tr_pt1[0] - x, tr_pt1[1] - y],\n",
    "                       [tr_pt2[0] - x, tr_pt2[1] - y],\n",
    "                       [tr_pt3[0] - x, tr_pt3[1] - y]], np.int32)\n",
    "\n",
    "    cv.fillConvexPoly(cropped_tr_mask, points, 255)\n",
    "    \n",
    "    return (x, y, w, h), cropped_tr_mask, np.float32(points)\n",
    "\n",
    "def face_to_swap(img1, detection_result1, video2, detection_result2):\n",
    "    try:\n",
    "        # Face 1 (to swap)\n",
    "        img1 = cv.cvtColor(img1, cv.COLOR_BGR2RGB) #if image\n",
    "        img_gray1 = cv.cvtColor(img1, cv.COLOR_BGR2GRAY)\n",
    "        mask = np.zeros_like(img_gray1)\n",
    "        face_landmarks1 = detection_result1.face_landmarks[0]\n",
    "\n",
    "        landmarks_points1 = get_landmark_points(face_landmarks1, img1)\n",
    "\n",
    "        points = np.array(landmarks_points1, np.int32)\n",
    "        convexhull = cv.convexHull(points)\n",
    "        cv.fillConvexPoly(mask, convexhull, 255)\n",
    "\n",
    "\t    # Delaunay triangulation\n",
    "        rect = cv.boundingRect(convexhull)\n",
    "        subdiv = cv.Subdiv2D(rect)\n",
    "        subdiv.insert(landmarks_points1)\n",
    "        triangles =  np.array(subdiv.getTriangleList(), dtype=np.int32)\n",
    "        indexes_triangles = get_index_triangles(points, triangles)\n",
    "\n",
    "        # Face 2 (dest)\n",
    "        annotated_video2_gray = cv.cvtColor(video2, cv.COLOR_BGR2GRAY)\n",
    "        face_landmarks2 = detection_result2.face_landmarks[0]\n",
    "        height, width, channels = video2.shape\n",
    "        video2_new_face = np.zeros((height, width, channels), np.uint8)  \n",
    "        landmarks_points2 = get_landmark_points(face_landmarks2, video2)\n",
    "\n",
    "        points2 = np.array(landmarks_points2, np.int32)\n",
    "        convexhull2 = cv.convexHull(points2)\n",
    "\n",
    "        for triangle_index in indexes_triangles:\n",
    "            # Triangulation of the first face\n",
    "            (x, y, w, h), cropped_tr1_mask1, points1 = triangulation(landmarks_points1, triangle_index)\n",
    "            cropped_triangle = img1[y: y + h, x: x + w]\n",
    "\n",
    "            # Triangulation of second face\n",
    "            (x, y, w, h), cropped_tr2_mask, points2 = triangulation(landmarks_points2, triangle_index)\n",
    "\n",
    "            # Warp triangles\n",
    "            M = cv.getAffineTransform(points1, points2)\n",
    "            warped_triangle = cv.warpAffine(cropped_triangle, M, (w, h))\n",
    "            warped_triangle = cv.bitwise_and(warped_triangle, warped_triangle, mask=cropped_tr2_mask)\n",
    "\n",
    "            # Reconstructing destination face\n",
    "            video2_new_face_rect_area = video2_new_face[y: y + h, x: x + w]\n",
    "            video2_new_face_rect_area_gray = cv.cvtColor(video2_new_face_rect_area, cv.COLOR_BGR2GRAY)\n",
    "            _, mask_triangles_designed = cv.threshold(video2_new_face_rect_area_gray, 1, 255, cv.THRESH_BINARY_INV)\n",
    "            warped_triangle = cv.bitwise_and(warped_triangle, warped_triangle, mask=mask_triangles_designed)\n",
    "\n",
    "            video2_new_face_rect_area = cv.add(video2_new_face_rect_area, warped_triangle)\n",
    "            video2_new_face[y: y + h, x: x + w] = video2_new_face_rect_area\n",
    "\n",
    "    except:\n",
    "        return video2\n",
    "    \n",
    "    # Face swapped (putting 1st face into 2nd face)\n",
    "    video2_face_mask = np.zeros_like(annotated_video2_gray)\n",
    "    video2_head_mask = cv.fillConvexPoly(video2_face_mask, convexhull2, 255)\n",
    "    video2_face_mask = cv.bitwise_not(video2_head_mask)\n",
    "\n",
    "    video2_head_noface = cv.bitwise_and(video2, video2, mask=video2_face_mask)\n",
    "    result = cv.add(video2_head_noface, video2_new_face)\n",
    "\n",
    "    (x, y, w, h) = cv.boundingRect(convexhull2)\n",
    "    center_face2 = (int((x + x + w) / 2), int((y + y + h) / 2))\n",
    "\n",
    "    output = cv.seamlessClone(result, video2, video2_head_mask, center_face2, cv.MIXED_CLONE)\n",
    "    kernel = np.ones((0, 0), np.uint8)\n",
    "    output = cv.morphologyEx(output, cv.MORPH_CLOSE, kernel)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicol\\miniconda3\\envs\\ia\\lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "BaseOptions = mp.tasks.BaseOptions\n",
    "FaceLandmarker = mp.tasks.vision.FaceLandmarker\n",
    "FaceLandmarkerOptions = mp.tasks.vision.FaceLandmarkerOptions\n",
    "VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "\n",
    "options = FaceLandmarkerOptions(\n",
    "    base_options=BaseOptions(model_asset_path=\"model/face_landmarker.task\"),\n",
    "    running_mode=VisionRunningMode.VIDEO)\n",
    "\n",
    "cam = cv.VideoCapture(0) \n",
    "cv.namedWindow(\"Cam\")    \n",
    "\n",
    "with FaceLandmarker.create_from_options(options) as landmarker:\n",
    "    mp_image = mp.Image.create_from_file(f\"{IMAGES_PATH}/ryan_reynolds.jpg\")\n",
    "    face_landmarker_org = landmarker.detect_for_video(mp_image, int(round(time.time() * 100)))\n",
    "    while cam.isOpened():\n",
    "        _, frame = cam.read()\n",
    "        cv.imshow(\"Cam\", frame)\n",
    "        mp_video = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame)\n",
    "        face_landmarker_dst = landmarker.detect_for_video(mp_video, int(round(time.time() * 100)))\n",
    "        output = face_to_swap(mp_image.numpy_view(), face_landmarker_org,\n",
    "                              mp_video.numpy_view(), face_landmarker_dst)\n",
    "        cv.imshow(\"Output\", output)\n",
    "\n",
    "        if cv.waitKey(10) & 0xFF == 27: cam.release()\n",
    "\n",
    "    cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
