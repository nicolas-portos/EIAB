{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      ":Number of Instances: 20640\n",
      "\n",
      ":Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      ":Attribute Information:\n",
      "    - MedInc        median income in block group\n",
      "    - HouseAge      median house age in block group\n",
      "    - AveRooms      average number of rooms per household\n",
      "    - AveBedrms     average number of bedrooms per household\n",
      "    - Population    block group population\n",
      "    - AveOccup      average number of household members\n",
      "    - Latitude      block group latitude\n",
      "    - Longitude     block group longitude\n",
      "\n",
      ":Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n",
      "\n",
      "The target variable is the median house value for California districts,\n",
      "expressed in hundreds of thousands of dollars ($100,000).\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "A household is a group of people residing within a home. Since the average\n",
      "number of rooms and bedrooms in this dataset are provided per household, these\n",
      "columns may take surprisingly large values for block groups with few households\n",
      "and many empty houses, such as vacation resorts.\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. rubric:: References\n",
      "\n",
      "- Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "  Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(housing[\"DESCR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = housing.data\n",
    "y = housing.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val =   scaler.transform(X_val)\n",
    "X_test =  scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.431, 0.708, 1.08 , ..., 2.53 , 1.5  , 1.585])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Api funcional\n",
    "inputs = keras.Input((8,))\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(inputs)\n",
    "outputs = keras.layers.Dense(1)(hidden1)\n",
    "model = keras.models.Model(inputs=[inputs], outputs=[outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Api subclase\n",
    "class RegCalifornia(keras.models.Model):\n",
    "    def __init__(self,shape=X_train.shape[1:], **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(30, activation=\"relu\")\n",
    "        self.outputs = keras.layers.Dense(1)\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        h1 = self.hidden1(inputs)\n",
    "        outputs = self.outputs(h1)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"modelito\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"modelito\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Activation_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Activation_layer (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │           \u001b[38;5;34m270\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m31\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">301</span> (1.18 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m301\u001b[0m (1.18 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">301</span> (1.18 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m301\u001b[0m (1.18 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(8,)),\n",
    "    # keras.layers.Dense(30, activation=\"relu\", input_shape=(8,)),\n",
    "    keras.layers.Dense(30, activation=\"relu\", name=\"Activation_layer\"),\n",
    "    keras.layers.Dense(1, name=\"Output_layer\")\n",
    "], name=\"modelito\")\n",
    "model.compile(optimizer= keras.optimizers.SGD(learning_rate=0.001),\n",
    "              loss=\"mean_squared_error\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.8500 - val_loss: 1.0025\n",
      "Epoch 2/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9148 - val_loss: 0.8045\n",
      "Epoch 3/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.7811 - val_loss: 0.7482\n",
      "Epoch 4/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.7299 - val_loss: 0.7052\n",
      "Epoch 5/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6907 - val_loss: 0.6695\n",
      "Epoch 6/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6584 - val_loss: 0.6391\n",
      "Epoch 7/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6308 - val_loss: 0.6135\n",
      "Epoch 8/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6074 - val_loss: 0.5911\n",
      "Epoch 9/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5875 - val_loss: 0.5723\n",
      "Epoch 10/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5709 - val_loss: 0.5561\n",
      "Epoch 11/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5567 - val_loss: 0.5422\n",
      "Epoch 12/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5449 - val_loss: 0.5303\n",
      "Epoch 13/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5349 - val_loss: 0.5200\n",
      "Epoch 14/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5264 - val_loss: 0.5112\n",
      "Epoch 15/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5191 - val_loss: 0.5035\n",
      "Epoch 16/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5129 - val_loss: 0.4970\n",
      "Epoch 17/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5077 - val_loss: 0.4913\n",
      "Epoch 18/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5031 - val_loss: 0.4863\n",
      "Epoch 19/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4991 - val_loss: 0.4820\n",
      "Epoch 20/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4956 - val_loss: 0.4782\n",
      "Epoch 21/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4925 - val_loss: 0.4748\n",
      "Epoch 22/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4897 - val_loss: 0.4717\n",
      "Epoch 23/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4871 - val_loss: 0.4688\n",
      "Epoch 24/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4848 - val_loss: 0.4662\n",
      "Epoch 25/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4825 - val_loss: 0.4638\n",
      "Epoch 26/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4804 - val_loss: 0.4615\n",
      "Epoch 27/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4784 - val_loss: 0.4594\n",
      "Epoch 28/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4765 - val_loss: 0.4573\n",
      "Epoch 29/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4747 - val_loss: 0.4554\n",
      "Epoch 30/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4729 - val_loss: 0.4536\n",
      "Epoch 31/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4712 - val_loss: 0.4518\n",
      "Epoch 32/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4696 - val_loss: 0.4501\n",
      "Epoch 33/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4680 - val_loss: 0.4485\n",
      "Epoch 34/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4664 - val_loss: 0.4470\n",
      "Epoch 35/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4650 - val_loss: 0.4456\n",
      "Epoch 36/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4636 - val_loss: 0.4442\n",
      "Epoch 37/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4622 - val_loss: 0.4429\n",
      "Epoch 38/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4609 - val_loss: 0.4416\n",
      "Epoch 39/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4596 - val_loss: 0.4403\n",
      "Epoch 40/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4584 - val_loss: 0.4391\n",
      "Epoch 41/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4571 - val_loss: 0.4379\n",
      "Epoch 42/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4559 - val_loss: 0.4368\n",
      "Epoch 43/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4548 - val_loss: 0.4356\n",
      "Epoch 44/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4536 - val_loss: 0.4345\n",
      "Epoch 45/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4524 - val_loss: 0.4334\n",
      "Epoch 46/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4513 - val_loss: 0.4323\n",
      "Epoch 47/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4501 - val_loss: 0.4312\n",
      "Epoch 48/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4489 - val_loss: 0.4301\n",
      "Epoch 49/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4477 - val_loss: 0.4291\n",
      "Epoch 50/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4466 - val_loss: 0.4281\n",
      "Epoch 51/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4455 - val_loss: 0.4271\n",
      "Epoch 52/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4444 - val_loss: 0.4262\n",
      "Epoch 53/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4433 - val_loss: 0.4253\n",
      "Epoch 54/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4423 - val_loss: 0.4242\n",
      "Epoch 55/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4413 - val_loss: 0.4232\n",
      "Epoch 56/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4403 - val_loss: 0.4224\n",
      "Epoch 57/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4394 - val_loss: 0.4215\n",
      "Epoch 58/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4386 - val_loss: 0.4208\n",
      "Epoch 59/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4377 - val_loss: 0.4200\n",
      "Epoch 60/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4369 - val_loss: 0.4193\n",
      "Epoch 61/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4360 - val_loss: 0.4186\n",
      "Epoch 62/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4352 - val_loss: 0.4179\n",
      "Epoch 63/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4345 - val_loss: 0.4172\n",
      "Epoch 64/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.4337 - val_loss: 0.4166\n",
      "Epoch 65/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4329 - val_loss: 0.4160\n",
      "Epoch 66/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4322 - val_loss: 0.4153\n",
      "Epoch 67/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4314 - val_loss: 0.4147\n",
      "Epoch 68/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4307 - val_loss: 0.4141\n",
      "Epoch 69/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4300 - val_loss: 0.4135\n",
      "Epoch 70/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4293 - val_loss: 0.4129\n",
      "Epoch 71/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4286 - val_loss: 0.4124\n",
      "Epoch 72/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - loss: 0.4279 - val_loss: 0.4118\n",
      "Epoch 73/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4272 - val_loss: 0.4112\n",
      "Epoch 74/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4265 - val_loss: 0.4106\n",
      "Epoch 75/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4258 - val_loss: 0.4101\n",
      "Epoch 76/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4252 - val_loss: 0.4095\n",
      "Epoch 77/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.4245 - val_loss: 0.4089\n",
      "Epoch 78/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4239 - val_loss: 0.4084\n",
      "Epoch 79/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4233 - val_loss: 0.4079\n",
      "Epoch 80/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4227 - val_loss: 0.4073\n",
      "Epoch 81/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4221 - val_loss: 0.4068\n",
      "Epoch 82/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4214 - val_loss: 0.4063\n",
      "Epoch 83/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4208 - val_loss: 0.4058\n",
      "Epoch 84/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4202 - val_loss: 0.4052\n",
      "Epoch 85/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4196 - val_loss: 0.4047\n",
      "Epoch 86/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4191 - val_loss: 0.4042\n",
      "Epoch 87/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4185 - val_loss: 0.4037\n",
      "Epoch 88/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4179 - val_loss: 0.4033\n",
      "Epoch 89/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4173 - val_loss: 0.4028\n",
      "Epoch 90/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4168 - val_loss: 0.4023\n",
      "Epoch 91/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4162 - val_loss: 0.4018\n",
      "Epoch 92/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4157 - val_loss: 0.4014\n",
      "Epoch 93/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4152 - val_loss: 0.4009\n",
      "Epoch 94/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4146 - val_loss: 0.4004\n",
      "Epoch 95/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4141 - val_loss: 0.4000\n",
      "Epoch 96/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4135 - val_loss: 0.3995\n",
      "Epoch 97/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4130 - val_loss: 0.3991\n",
      "Epoch 98/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4124 - val_loss: 0.3986\n",
      "Epoch 99/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4118 - val_loss: 0.3982\n",
      "Epoch 100/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4113 - val_loss: 0.3977\n",
      "Epoch 101/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4107 - val_loss: 0.3973\n",
      "Epoch 102/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4101 - val_loss: 0.3969\n",
      "Epoch 103/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4096 - val_loss: 0.3964\n",
      "Epoch 104/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4090 - val_loss: 0.3960\n",
      "Epoch 105/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4084 - val_loss: 0.3956\n",
      "Epoch 106/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4079 - val_loss: 0.3952\n",
      "Epoch 107/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4074 - val_loss: 0.3947\n",
      "Epoch 108/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4068 - val_loss: 0.3942\n",
      "Epoch 109/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4063 - val_loss: 0.3938\n",
      "Epoch 110/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - loss: 0.4058 - val_loss: 0.3934\n",
      "Epoch 111/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - loss: 0.4053 - val_loss: 0.3930\n",
      "Epoch 112/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4048 - val_loss: 0.3926\n",
      "Epoch 113/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4043 - val_loss: 0.3922\n",
      "Epoch 114/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4038 - val_loss: 0.3918\n",
      "Epoch 115/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4033 - val_loss: 0.3914\n",
      "Epoch 116/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4028 - val_loss: 0.3910\n",
      "Epoch 117/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4023 - val_loss: 0.3906\n",
      "Epoch 118/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4018 - val_loss: 0.3903\n",
      "Epoch 119/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4013 - val_loss: 0.3899\n",
      "Epoch 120/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4009 - val_loss: 0.3895\n",
      "Epoch 121/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4004 - val_loss: 0.3891\n",
      "Epoch 122/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3999 - val_loss: 0.3888\n",
      "Epoch 123/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3995 - val_loss: 0.3884\n",
      "Epoch 124/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3991 - val_loss: 0.3881\n",
      "Epoch 125/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - loss: 0.3986 - val_loss: 0.3877\n",
      "Epoch 126/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - loss: 0.3982 - val_loss: 0.3874\n",
      "Epoch 127/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - loss: 0.3977 - val_loss: 0.3871\n",
      "Epoch 128/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3973 - val_loss: 0.3868\n",
      "Epoch 129/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3969 - val_loss: 0.3864\n",
      "Epoch 130/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3965 - val_loss: 0.3861\n",
      "Epoch 131/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3960 - val_loss: 0.3858\n",
      "Epoch 132/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3956 - val_loss: 0.3855\n",
      "Epoch 133/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3952 - val_loss: 0.3852\n",
      "Epoch 134/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3948 - val_loss: 0.3849\n",
      "Epoch 135/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - loss: 0.3944 - val_loss: 0.3845\n",
      "Epoch 136/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3940 - val_loss: 0.3842\n",
      "Epoch 137/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3936 - val_loss: 0.3839\n",
      "Epoch 138/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3933 - val_loss: 0.3837\n",
      "Epoch 139/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3929 - val_loss: 0.3834\n",
      "Epoch 140/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3925 - val_loss: 0.3830\n",
      "Epoch 141/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3922 - val_loss: 0.3827\n",
      "Epoch 142/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3918 - val_loss: 0.3824\n",
      "Epoch 143/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3914 - val_loss: 0.3821\n",
      "Epoch 144/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3911 - val_loss: 0.3819\n",
      "Epoch 145/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3907 - val_loss: 0.3816\n",
      "Epoch 146/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3904 - val_loss: 0.3813\n",
      "Epoch 147/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3900 - val_loss: 0.3810\n",
      "Epoch 148/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3896 - val_loss: 0.3807\n",
      "Epoch 149/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - loss: 0.3893 - val_loss: 0.3805\n",
      "Epoch 150/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3889 - val_loss: 0.3802\n",
      "Epoch 151/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3886 - val_loss: 0.3799\n",
      "Epoch 152/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3882 - val_loss: 0.3797\n",
      "Epoch 153/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3879 - val_loss: 0.3794\n",
      "Epoch 154/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3875 - val_loss: 0.3791\n",
      "Epoch 155/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3872 - val_loss: 0.3789\n",
      "Epoch 156/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3869 - val_loss: 0.3786\n",
      "Epoch 157/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3865 - val_loss: 0.3784\n",
      "Epoch 158/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3862 - val_loss: 0.3781\n",
      "Epoch 159/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3859 - val_loss: 0.3778\n",
      "Epoch 160/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3856 - val_loss: 0.3776\n",
      "Epoch 161/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3852 - val_loss: 0.3773\n",
      "Epoch 162/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3849 - val_loss: 0.3771\n",
      "Epoch 163/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3846 - val_loss: 0.3769\n",
      "Epoch 164/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3843 - val_loss: 0.3766\n",
      "Epoch 165/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3840 - val_loss: 0.3764\n",
      "Epoch 166/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3837 - val_loss: 0.3761\n",
      "Epoch 167/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3835 - val_loss: 0.3759\n",
      "Epoch 168/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3832 - val_loss: 0.3757\n",
      "Epoch 169/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3829 - val_loss: 0.3755\n",
      "Epoch 170/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3826 - val_loss: 0.3752\n",
      "Epoch 171/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3823 - val_loss: 0.3750\n",
      "Epoch 172/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3820 - val_loss: 0.3748\n",
      "Epoch 173/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3818 - val_loss: 0.3746\n",
      "Epoch 174/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3815 - val_loss: 0.3744\n",
      "Epoch 175/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3812 - val_loss: 0.3741\n",
      "Epoch 176/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3809 - val_loss: 0.3739\n",
      "Epoch 177/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3807 - val_loss: 0.3737\n",
      "Epoch 178/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3804 - val_loss: 0.3735\n",
      "Epoch 179/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3801 - val_loss: 0.3733\n",
      "Epoch 180/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3799 - val_loss: 0.3731\n",
      "Epoch 181/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3796 - val_loss: 0.3729\n",
      "Epoch 182/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3793 - val_loss: 0.3727\n",
      "Epoch 183/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3790 - val_loss: 0.3725\n",
      "Epoch 184/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3788 - val_loss: 0.3722\n",
      "Epoch 185/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3785 - val_loss: 0.3720\n",
      "Epoch 186/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3782 - val_loss: 0.3718\n",
      "Epoch 187/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3779 - val_loss: 0.3716\n",
      "Epoch 188/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3777 - val_loss: 0.3714\n",
      "Epoch 189/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3774 - val_loss: 0.3712\n",
      "Epoch 190/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3771 - val_loss: 0.3710\n",
      "Epoch 191/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3769 - val_loss: 0.3708\n",
      "Epoch 192/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3766 - val_loss: 0.3706\n",
      "Epoch 193/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3763 - val_loss: 0.3704\n",
      "Epoch 194/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3761 - val_loss: 0.3702\n",
      "Epoch 195/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3758 - val_loss: 0.3700\n",
      "Epoch 196/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3756 - val_loss: 0.3698\n",
      "Epoch 197/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3753 - val_loss: 0.3696\n",
      "Epoch 198/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3751 - val_loss: 0.3695\n",
      "Epoch 199/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3749 - val_loss: 0.3693\n",
      "Epoch 200/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - loss: 0.3746 - val_loss: 0.3691\n",
      "Epoch 201/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3744 - val_loss: 0.3689\n",
      "Epoch 202/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - loss: 0.3742 - val_loss: 0.3687\n",
      "Epoch 203/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - loss: 0.3740 - val_loss: 0.3686\n",
      "Epoch 204/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - loss: 0.3737 - val_loss: 0.3684\n",
      "Epoch 205/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - loss: 0.3735 - val_loss: 0.3683\n",
      "Epoch 206/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3733 - val_loss: 0.3681\n",
      "Epoch 207/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - loss: 0.3731 - val_loss: 0.3679\n",
      "Epoch 208/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - loss: 0.3729 - val_loss: 0.3678\n",
      "Epoch 209/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - loss: 0.3727 - val_loss: 0.3676\n",
      "Epoch 210/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3725 - val_loss: 0.3675\n",
      "Epoch 211/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - loss: 0.3723 - val_loss: 0.3673\n",
      "Epoch 212/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - loss: 0.3721 - val_loss: 0.3671\n",
      "Epoch 213/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3719 - val_loss: 0.3670\n",
      "Epoch 214/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3717 - val_loss: 0.3668\n",
      "Epoch 215/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - loss: 0.3715 - val_loss: 0.3666\n",
      "Epoch 216/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3713 - val_loss: 0.3665\n",
      "Epoch 217/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3711 - val_loss: 0.3663\n",
      "Epoch 218/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - loss: 0.3709 - val_loss: 0.3661\n",
      "Epoch 219/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3707 - val_loss: 0.3660\n",
      "Epoch 220/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3705 - val_loss: 0.3658\n",
      "Epoch 221/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3703 - val_loss: 0.3657\n",
      "Epoch 222/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3701 - val_loss: 0.3655\n",
      "Epoch 223/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3699 - val_loss: 0.3654\n",
      "Epoch 224/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - loss: 0.3698 - val_loss: 0.3652\n",
      "Epoch 225/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - loss: 0.3696 - val_loss: 0.3651\n",
      "Epoch 226/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3694 - val_loss: 0.3650\n",
      "Epoch 227/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3692 - val_loss: 0.3648\n",
      "Epoch 228/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3690 - val_loss: 0.3647\n",
      "Epoch 229/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3689 - val_loss: 0.3645\n",
      "Epoch 230/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3687 - val_loss: 0.3644\n",
      "Epoch 231/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3685 - val_loss: 0.3642\n",
      "Epoch 232/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3683 - val_loss: 0.3641\n",
      "Epoch 233/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3682 - val_loss: 0.3640\n",
      "Epoch 234/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3680 - val_loss: 0.3638\n",
      "Epoch 235/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3678 - val_loss: 0.3637\n",
      "Epoch 236/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3676 - val_loss: 0.3636\n",
      "Epoch 237/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3675 - val_loss: 0.3634\n",
      "Epoch 238/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - loss: 0.3673 - val_loss: 0.3633\n",
      "Epoch 239/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3671 - val_loss: 0.3632\n",
      "Epoch 240/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3670 - val_loss: 0.3630\n",
      "Epoch 241/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3668 - val_loss: 0.3629\n",
      "Epoch 242/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3666 - val_loss: 0.3627\n",
      "Epoch 243/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3665 - val_loss: 0.3625\n",
      "Epoch 244/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - loss: 0.3663 - val_loss: 0.3624\n",
      "Epoch 245/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3662 - val_loss: 0.3623\n",
      "Epoch 246/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3660 - val_loss: 0.3621\n",
      "Epoch 247/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3659 - val_loss: 0.3620\n",
      "Epoch 248/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - loss: 0.3657 - val_loss: 0.3618\n",
      "Epoch 249/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - loss: 0.3656 - val_loss: 0.3617\n",
      "Epoch 250/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3654 - val_loss: 0.3615\n",
      "Epoch 251/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - loss: 0.3652 - val_loss: 0.3614\n",
      "Epoch 252/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3651 - val_loss: 0.3613\n",
      "Epoch 253/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3649 - val_loss: 0.3611\n",
      "Epoch 254/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3648 - val_loss: 0.3610\n",
      "Epoch 255/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3646 - val_loss: 0.3608\n",
      "Epoch 256/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3645 - val_loss: 0.3607\n",
      "Epoch 257/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - loss: 0.3643 - val_loss: 0.3606\n",
      "Epoch 258/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - loss: 0.3642 - val_loss: 0.3604\n",
      "Epoch 259/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3641 - val_loss: 0.3603\n",
      "Epoch 260/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3639 - val_loss: 0.3601\n",
      "Epoch 261/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3638 - val_loss: 0.3600\n",
      "Epoch 262/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3636 - val_loss: 0.3599\n",
      "Epoch 263/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3635 - val_loss: 0.3597\n",
      "Epoch 264/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3634 - val_loss: 0.3596\n",
      "Epoch 265/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3632 - val_loss: 0.3595\n",
      "Epoch 266/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3631 - val_loss: 0.3593\n",
      "Epoch 267/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3629 - val_loss: 0.3592\n",
      "Epoch 268/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3628 - val_loss: 0.3591\n",
      "Epoch 269/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3627 - val_loss: 0.3589\n",
      "Epoch 270/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3625 - val_loss: 0.3588\n",
      "Epoch 271/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3624 - val_loss: 0.3587\n",
      "Epoch 272/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3622 - val_loss: 0.3585\n",
      "Epoch 273/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3621 - val_loss: 0.3584\n",
      "Epoch 274/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3620 - val_loss: 0.3583\n",
      "Epoch 275/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3619 - val_loss: 0.3582\n",
      "Epoch 276/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3617 - val_loss: 0.3580\n",
      "Epoch 277/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3616 - val_loss: 0.3579\n",
      "Epoch 278/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3615 - val_loss: 0.3578\n",
      "Epoch 279/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3613 - val_loss: 0.3577\n",
      "Epoch 280/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3612 - val_loss: 0.3576\n",
      "Epoch 281/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3611 - val_loss: 0.3574\n",
      "Epoch 282/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3610 - val_loss: 0.3573\n",
      "Epoch 283/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3608 - val_loss: 0.3572\n",
      "Epoch 284/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3607 - val_loss: 0.3571\n",
      "Epoch 285/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3606 - val_loss: 0.3570\n",
      "Epoch 286/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3605 - val_loss: 0.3569\n",
      "Epoch 287/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3603 - val_loss: 0.3567\n",
      "Epoch 288/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3602 - val_loss: 0.3566\n",
      "Epoch 289/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3601 - val_loss: 0.3565\n",
      "Epoch 290/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - loss: 0.3600 - val_loss: 0.3564\n",
      "Epoch 291/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3598 - val_loss: 0.3563\n",
      "Epoch 292/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3597 - val_loss: 0.3562\n",
      "Epoch 293/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3596 - val_loss: 0.3561\n",
      "Epoch 294/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3595 - val_loss: 0.3560\n",
      "Epoch 295/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3593 - val_loss: 0.3559\n",
      "Epoch 296/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3592 - val_loss: 0.3558\n",
      "Epoch 297/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3591 - val_loss: 0.3557\n",
      "Epoch 298/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3590 - val_loss: 0.3556\n",
      "Epoch 299/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3589 - val_loss: 0.3554\n",
      "Epoch 300/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3587 - val_loss: 0.3553\n",
      "Epoch 301/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3586 - val_loss: 0.3552\n",
      "Epoch 302/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3585 - val_loss: 0.3551\n",
      "Epoch 303/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3584 - val_loss: 0.3550\n",
      "Epoch 304/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3583 - val_loss: 0.3549\n",
      "Epoch 305/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3582 - val_loss: 0.3548\n",
      "Epoch 306/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3581 - val_loss: 0.3547\n",
      "Epoch 307/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3579 - val_loss: 0.3546\n",
      "Epoch 308/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3578 - val_loss: 0.3545\n",
      "Epoch 309/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3577 - val_loss: 0.3544\n",
      "Epoch 310/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3576 - val_loss: 0.3543\n",
      "Epoch 311/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3575 - val_loss: 0.3542\n",
      "Epoch 312/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3573 - val_loss: 0.3541\n",
      "Epoch 313/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3572 - val_loss: 0.3540\n",
      "Epoch 314/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3571 - val_loss: 0.3539\n",
      "Epoch 315/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3570 - val_loss: 0.3539\n",
      "Epoch 316/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3569 - val_loss: 0.3538\n",
      "Epoch 317/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3568 - val_loss: 0.3537\n",
      "Epoch 318/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3566 - val_loss: 0.3536\n",
      "Epoch 319/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3565 - val_loss: 0.3535\n",
      "Epoch 320/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3564 - val_loss: 0.3534\n",
      "Epoch 321/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3563 - val_loss: 0.3533\n",
      "Epoch 322/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3562 - val_loss: 0.3532\n",
      "Epoch 323/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3561 - val_loss: 0.3531\n",
      "Epoch 324/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3560 - val_loss: 0.3530\n",
      "Epoch 325/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3559 - val_loss: 0.3529\n",
      "Epoch 326/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3557 - val_loss: 0.3528\n",
      "Epoch 327/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3556 - val_loss: 0.3527\n",
      "Epoch 328/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3555 - val_loss: 0.3526\n",
      "Epoch 329/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3554 - val_loss: 0.3525\n",
      "Epoch 330/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3553 - val_loss: 0.3524\n",
      "Epoch 331/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3552 - val_loss: 0.3524\n",
      "Epoch 332/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3551 - val_loss: 0.3523\n",
      "Epoch 333/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3549 - val_loss: 0.3522\n",
      "Epoch 334/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3548 - val_loss: 0.3521\n",
      "Epoch 335/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3547 - val_loss: 0.3520\n",
      "Epoch 336/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3546 - val_loss: 0.3519\n",
      "Epoch 337/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3545 - val_loss: 0.3518\n",
      "Epoch 338/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3544 - val_loss: 0.3518\n",
      "Epoch 339/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3543 - val_loss: 0.3517\n",
      "Epoch 340/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3542 - val_loss: 0.3516\n",
      "Epoch 341/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3541 - val_loss: 0.3515\n",
      "Epoch 342/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3540 - val_loss: 0.3514\n",
      "Epoch 343/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - loss: 0.3539 - val_loss: 0.3513\n",
      "Epoch 344/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - loss: 0.3538 - val_loss: 0.3513\n",
      "Epoch 345/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - loss: 0.3537 - val_loss: 0.3512\n",
      "Epoch 346/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - loss: 0.3536 - val_loss: 0.3511\n",
      "Epoch 347/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - loss: 0.3535 - val_loss: 0.3510\n",
      "Epoch 348/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - loss: 0.3534 - val_loss: 0.3509\n",
      "Epoch 349/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - loss: 0.3533 - val_loss: 0.3508\n",
      "Epoch 350/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - loss: 0.3532 - val_loss: 0.3508\n",
      "Epoch 351/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3531 - val_loss: 0.3507\n",
      "Epoch 352/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3530 - val_loss: 0.3506\n",
      "Epoch 353/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - loss: 0.3529 - val_loss: 0.3505\n",
      "Epoch 354/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3527 - val_loss: 0.3504\n",
      "Epoch 355/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - loss: 0.3526 - val_loss: 0.3503\n",
      "Epoch 356/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - loss: 0.3525 - val_loss: 0.3503\n",
      "Epoch 357/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - loss: 0.3524 - val_loss: 0.3502\n",
      "Epoch 358/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - loss: 0.3523 - val_loss: 0.3501\n",
      "Epoch 359/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - loss: 0.3522 - val_loss: 0.3500\n",
      "Epoch 360/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3521 - val_loss: 0.3499\n",
      "Epoch 361/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - loss: 0.3520 - val_loss: 0.3498\n",
      "Epoch 362/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - loss: 0.3519 - val_loss: 0.3497\n",
      "Epoch 363/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - loss: 0.3518 - val_loss: 0.3496\n",
      "Epoch 364/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - loss: 0.3517 - val_loss: 0.3495\n",
      "Epoch 365/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - loss: 0.3516 - val_loss: 0.3494\n",
      "Epoch 366/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3515 - val_loss: 0.3493\n",
      "Epoch 367/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - loss: 0.3514 - val_loss: 0.3492\n",
      "Epoch 368/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - loss: 0.3512 - val_loss: 0.3491\n",
      "Epoch 369/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - loss: 0.3511 - val_loss: 0.3490\n",
      "Epoch 370/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - loss: 0.3510 - val_loss: 0.3489\n",
      "Epoch 371/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - loss: 0.3509 - val_loss: 0.3488\n",
      "Epoch 372/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3508 - val_loss: 0.3487\n",
      "Epoch 373/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - loss: 0.3507 - val_loss: 0.3486\n",
      "Epoch 374/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - loss: 0.3505 - val_loss: 0.3484\n",
      "Epoch 375/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - loss: 0.3504 - val_loss: 0.3483\n",
      "Epoch 376/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - loss: 0.3503 - val_loss: 0.3482\n",
      "Epoch 377/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - loss: 0.3502 - val_loss: 0.3481\n",
      "Epoch 378/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3501 - val_loss: 0.3480\n",
      "Epoch 379/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - loss: 0.3499 - val_loss: 0.3479\n",
      "Epoch 380/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - loss: 0.3498 - val_loss: 0.3479\n",
      "Epoch 381/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - loss: 0.3497 - val_loss: 0.3477\n",
      "Epoch 382/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - loss: 0.3496 - val_loss: 0.3476\n",
      "Epoch 383/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3495 - val_loss: 0.3476\n",
      "Epoch 384/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - loss: 0.3494 - val_loss: 0.3475\n",
      "Epoch 385/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - loss: 0.3492 - val_loss: 0.3473\n",
      "Epoch 386/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - loss: 0.3491 - val_loss: 0.3473\n",
      "Epoch 387/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - loss: 0.3490 - val_loss: 0.3472\n",
      "Epoch 388/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - loss: 0.3489 - val_loss: 0.3471\n",
      "Epoch 389/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3488 - val_loss: 0.3470\n",
      "Epoch 390/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - loss: 0.3487 - val_loss: 0.3469\n",
      "Epoch 391/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - loss: 0.3486 - val_loss: 0.3468\n",
      "Epoch 392/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - loss: 0.3484 - val_loss: 0.3467\n",
      "Epoch 393/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - loss: 0.3483 - val_loss: 0.3466\n",
      "Epoch 394/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - loss: 0.3482 - val_loss: 0.3465\n",
      "Epoch 395/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3481 - val_loss: 0.3464\n",
      "Epoch 396/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - loss: 0.3480 - val_loss: 0.3463\n",
      "Epoch 397/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - loss: 0.3478 - val_loss: 0.3462\n",
      "Epoch 398/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - loss: 0.3477 - val_loss: 0.3461\n",
      "Epoch 399/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - loss: 0.3476 - val_loss: 0.3460\n",
      "Epoch 400/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - loss: 0.3475 - val_loss: 0.3459\n",
      "Epoch 401/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - loss: 0.3474 - val_loss: 0.3458\n",
      "Epoch 402/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - loss: 0.3473 - val_loss: 0.3457\n",
      "Epoch 403/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - loss: 0.3471 - val_loss: 0.3456\n",
      "Epoch 404/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - loss: 0.3470 - val_loss: 0.3455\n",
      "Epoch 405/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - loss: 0.3469 - val_loss: 0.3454\n",
      "Epoch 406/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3468 - val_loss: 0.3453\n",
      "Epoch 407/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - loss: 0.3467 - val_loss: 0.3452\n",
      "Epoch 408/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - loss: 0.3465 - val_loss: 0.3451\n",
      "Epoch 409/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - loss: 0.3464 - val_loss: 0.3450\n",
      "Epoch 410/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - loss: 0.3463 - val_loss: 0.3449\n",
      "Epoch 411/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - loss: 0.3462 - val_loss: 0.3448\n",
      "Epoch 412/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3461 - val_loss: 0.3447\n",
      "Epoch 413/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - loss: 0.3459 - val_loss: 0.3446\n",
      "Epoch 414/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - loss: 0.3458 - val_loss: 0.3445\n",
      "Epoch 415/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - loss: 0.3457 - val_loss: 0.3443\n",
      "Epoch 416/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - loss: 0.3456 - val_loss: 0.3442\n",
      "Epoch 417/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3454 - val_loss: 0.3441\n",
      "Epoch 418/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - loss: 0.3453 - val_loss: 0.3440\n",
      "Epoch 419/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - loss: 0.3452 - val_loss: 0.3439\n",
      "Epoch 420/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - loss: 0.3450 - val_loss: 0.3438\n",
      "Epoch 421/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - loss: 0.3449 - val_loss: 0.3436\n",
      "Epoch 422/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - loss: 0.3447 - val_loss: 0.3435\n",
      "Epoch 423/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3446 - val_loss: 0.3434\n",
      "Epoch 424/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - loss: 0.3445 - val_loss: 0.3433\n",
      "Epoch 425/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - loss: 0.3444 - val_loss: 0.3432\n",
      "Epoch 426/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - loss: 0.3442 - val_loss: 0.3431\n",
      "Epoch 427/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - loss: 0.3441 - val_loss: 0.3430\n",
      "Epoch 428/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3440 - val_loss: 0.3428\n",
      "Epoch 429/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - loss: 0.3438 - val_loss: 0.3427\n",
      "Epoch 430/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - loss: 0.3437 - val_loss: 0.3426\n",
      "Epoch 431/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - loss: 0.3436 - val_loss: 0.3425\n",
      "Epoch 432/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - loss: 0.3434 - val_loss: 0.3424\n",
      "Epoch 433/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - loss: 0.3433 - val_loss: 0.3422\n",
      "Epoch 434/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3432 - val_loss: 0.3421\n",
      "Epoch 435/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - loss: 0.3431 - val_loss: 0.3420\n",
      "Epoch 436/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - loss: 0.3429 - val_loss: 0.3419\n",
      "Epoch 437/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - loss: 0.3428 - val_loss: 0.3418\n",
      "Epoch 438/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - loss: 0.3427 - val_loss: 0.3416\n",
      "Epoch 439/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3425 - val_loss: 0.3415\n",
      "Epoch 440/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - loss: 0.3424 - val_loss: 0.3414\n",
      "Epoch 441/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - loss: 0.3423 - val_loss: 0.3413\n",
      "Epoch 442/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - loss: 0.3422 - val_loss: 0.3412\n",
      "Epoch 443/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - loss: 0.3420 - val_loss: 0.3411\n",
      "Epoch 444/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - loss: 0.3419 - val_loss: 0.3410\n",
      "Epoch 445/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3418 - val_loss: 0.3409\n",
      "Epoch 446/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - loss: 0.3417 - val_loss: 0.3408\n",
      "Epoch 447/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - loss: 0.3416 - val_loss: 0.3407\n",
      "Epoch 448/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - loss: 0.3414 - val_loss: 0.3406\n",
      "Epoch 449/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - loss: 0.3413 - val_loss: 0.3405\n",
      "Epoch 450/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3412 - val_loss: 0.3404\n",
      "Epoch 451/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - loss: 0.3411 - val_loss: 0.3403\n",
      "Epoch 452/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - loss: 0.3410 - val_loss: 0.3402\n",
      "Epoch 453/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - loss: 0.3408 - val_loss: 0.3401\n",
      "Epoch 454/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - loss: 0.3407 - val_loss: 0.3400\n",
      "Epoch 455/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3406 - val_loss: 0.3399\n",
      "Epoch 456/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - loss: 0.3405 - val_loss: 0.3398\n",
      "Epoch 457/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - loss: 0.3404 - val_loss: 0.3397\n",
      "Epoch 458/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - loss: 0.3403 - val_loss: 0.3396\n",
      "Epoch 459/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - loss: 0.3402 - val_loss: 0.3395\n",
      "Epoch 460/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3400 - val_loss: 0.3394\n",
      "Epoch 461/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - loss: 0.3399 - val_loss: 0.3393\n",
      "Epoch 462/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - loss: 0.3398 - val_loss: 0.3392\n",
      "Epoch 463/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - loss: 0.3397 - val_loss: 0.3391\n",
      "Epoch 464/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - loss: 0.3396 - val_loss: 0.3390\n",
      "Epoch 465/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3395 - val_loss: 0.3389\n",
      "Epoch 466/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3394 - val_loss: 0.3388\n",
      "Epoch 467/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - loss: 0.3392 - val_loss: 0.3387\n",
      "Epoch 468/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - loss: 0.3391 - val_loss: 0.3386\n",
      "Epoch 469/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - loss: 0.3390 - val_loss: 0.3385\n",
      "Epoch 470/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3389 - val_loss: 0.3384\n",
      "Epoch 471/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - loss: 0.3388 - val_loss: 0.3383\n",
      "Epoch 472/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - loss: 0.3387 - val_loss: 0.3382\n",
      "Epoch 473/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - loss: 0.3386 - val_loss: 0.3381\n",
      "Epoch 474/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - loss: 0.3385 - val_loss: 0.3381\n",
      "Epoch 475/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3383 - val_loss: 0.3380\n",
      "Epoch 476/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3382 - val_loss: 0.3379\n",
      "Epoch 477/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3381 - val_loss: 0.3378\n",
      "Epoch 478/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3380 - val_loss: 0.3377\n",
      "Epoch 479/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3379 - val_loss: 0.3377\n",
      "Epoch 480/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3378 - val_loss: 0.3376\n",
      "Epoch 481/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3377 - val_loss: 0.3375\n",
      "Epoch 482/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3376 - val_loss: 0.3374\n",
      "Epoch 483/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3375 - val_loss: 0.3373\n",
      "Epoch 484/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - loss: 0.3373 - val_loss: 0.3372\n",
      "Epoch 485/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - loss: 0.3372 - val_loss: 0.3372\n",
      "Epoch 486/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - loss: 0.3371 - val_loss: 0.3371\n",
      "Epoch 487/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - loss: 0.3370 - val_loss: 0.3370\n",
      "Epoch 488/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - loss: 0.3369 - val_loss: 0.3369\n",
      "Epoch 489/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3368 - val_loss: 0.3368\n",
      "Epoch 490/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3367 - val_loss: 0.3367\n",
      "Epoch 491/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3366 - val_loss: 0.3366\n",
      "Epoch 492/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3365 - val_loss: 0.3365\n",
      "Epoch 493/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3364 - val_loss: 0.3364\n",
      "Epoch 494/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3363 - val_loss: 0.3364\n",
      "Epoch 495/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3361 - val_loss: 0.3363\n",
      "Epoch 496/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - loss: 0.3360 - val_loss: 0.3363\n",
      "Epoch 497/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3359 - val_loss: 0.3362\n",
      "Epoch 498/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3358 - val_loss: 0.3361\n",
      "Epoch 499/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3357 - val_loss: 0.3361\n",
      "Epoch 500/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3356 - val_loss: 0.3360\n",
      "Epoch 501/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3355 - val_loss: 0.3360\n",
      "Epoch 502/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3354 - val_loss: 0.3359\n",
      "Epoch 503/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3353 - val_loss: 0.3358\n",
      "Epoch 504/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3352 - val_loss: 0.3357\n",
      "Epoch 505/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3351 - val_loss: 0.3357\n",
      "Epoch 506/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3350 - val_loss: 0.3356\n",
      "Epoch 507/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3349 - val_loss: 0.3356\n",
      "Epoch 508/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3348 - val_loss: 0.3355\n",
      "Epoch 509/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3347 - val_loss: 0.3354\n",
      "Epoch 510/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3346 - val_loss: 0.3353\n",
      "Epoch 511/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3345 - val_loss: 0.3352\n",
      "Epoch 512/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3344 - val_loss: 0.3351\n",
      "Epoch 513/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3343 - val_loss: 0.3351\n",
      "Epoch 514/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3342 - val_loss: 0.3350\n",
      "Epoch 515/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3341 - val_loss: 0.3349\n",
      "Epoch 516/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3340 - val_loss: 0.3348\n",
      "Epoch 517/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3339 - val_loss: 0.3347\n",
      "Epoch 518/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3338 - val_loss: 0.3346\n",
      "Epoch 519/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3337 - val_loss: 0.3346\n",
      "Epoch 520/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3336 - val_loss: 0.3345\n",
      "Epoch 521/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3335 - val_loss: 0.3344\n",
      "Epoch 522/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - loss: 0.3334 - val_loss: 0.3343\n",
      "Epoch 523/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - loss: 0.3333 - val_loss: 0.3342\n",
      "Epoch 524/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3332 - val_loss: 0.3342\n",
      "Epoch 525/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3331 - val_loss: 0.3341\n",
      "Epoch 526/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3330 - val_loss: 0.3340\n",
      "Epoch 527/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3329 - val_loss: 0.3339\n",
      "Epoch 528/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3328 - val_loss: 0.3339\n",
      "Epoch 529/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3327 - val_loss: 0.3338\n",
      "Epoch 530/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3326 - val_loss: 0.3337\n",
      "Epoch 531/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3325 - val_loss: 0.3337\n",
      "Epoch 532/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - loss: 0.3324 - val_loss: 0.3336\n",
      "Epoch 533/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3323 - val_loss: 0.3335\n",
      "Epoch 534/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3322 - val_loss: 0.3334\n",
      "Epoch 535/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3321 - val_loss: 0.3334\n",
      "Epoch 536/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3320 - val_loss: 0.3333\n",
      "Epoch 537/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3319 - val_loss: 0.3332\n",
      "Epoch 538/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3318 - val_loss: 0.3332\n",
      "Epoch 539/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3317 - val_loss: 0.3331\n",
      "Epoch 540/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3316 - val_loss: 0.3330\n",
      "Epoch 541/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3315 - val_loss: 0.3329\n",
      "Epoch 542/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3314 - val_loss: 0.3329\n",
      "Epoch 543/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3313 - val_loss: 0.3327\n",
      "Epoch 544/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3312 - val_loss: 0.3327\n",
      "Epoch 545/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3311 - val_loss: 0.3326\n",
      "Epoch 546/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3310 - val_loss: 0.3325\n",
      "Epoch 547/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3309 - val_loss: 0.3324\n",
      "Epoch 548/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3308 - val_loss: 0.3324\n",
      "Epoch 549/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step - loss: 0.3307 - val_loss: 0.3323\n",
      "Epoch 550/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3306 - val_loss: 0.3322\n",
      "Epoch 551/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3305 - val_loss: 0.3322\n",
      "Epoch 552/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3304 - val_loss: 0.3321\n",
      "Epoch 553/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3303 - val_loss: 0.3320\n",
      "Epoch 554/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3302 - val_loss: 0.3319\n",
      "Epoch 555/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3301 - val_loss: 0.3318\n",
      "Epoch 556/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3300 - val_loss: 0.3318\n",
      "Epoch 557/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3299 - val_loss: 0.3317\n",
      "Epoch 558/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - loss: 0.3298 - val_loss: 0.3316\n",
      "Epoch 559/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3297 - val_loss: 0.3315\n",
      "Epoch 560/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3296 - val_loss: 0.3314\n",
      "Epoch 561/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3295 - val_loss: 0.3314\n",
      "Epoch 562/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3294 - val_loss: 0.3313\n",
      "Epoch 563/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3293 - val_loss: 0.3312\n",
      "Epoch 564/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3292 - val_loss: 0.3311\n",
      "Epoch 565/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3291 - val_loss: 0.3309\n",
      "Epoch 566/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3290 - val_loss: 0.3308\n",
      "Epoch 567/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3289 - val_loss: 0.3307\n",
      "Epoch 568/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3288 - val_loss: 0.3306\n",
      "Epoch 569/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3287 - val_loss: 0.3305\n",
      "Epoch 570/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3287 - val_loss: 0.3304\n",
      "Epoch 571/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3286 - val_loss: 0.3303\n",
      "Epoch 572/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3285 - val_loss: 0.3302\n",
      "Epoch 573/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3284 - val_loss: 0.3301\n",
      "Epoch 574/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3283 - val_loss: 0.3300\n",
      "Epoch 575/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3282 - val_loss: 0.3299\n",
      "Epoch 576/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3281 - val_loss: 0.3298\n",
      "Epoch 577/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3280 - val_loss: 0.3297\n",
      "Epoch 578/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3279 - val_loss: 0.3296\n",
      "Epoch 579/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3278 - val_loss: 0.3295\n",
      "Epoch 580/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3277 - val_loss: 0.3294\n",
      "Epoch 581/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3276 - val_loss: 0.3293\n",
      "Epoch 582/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3275 - val_loss: 0.3292\n",
      "Epoch 583/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3274 - val_loss: 0.3292\n",
      "Epoch 584/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3274 - val_loss: 0.3291\n",
      "Epoch 585/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3273 - val_loss: 0.3290\n",
      "Epoch 586/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - loss: 0.3272 - val_loss: 0.3290\n",
      "Epoch 587/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - loss: 0.3271 - val_loss: 0.3289\n",
      "Epoch 588/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3270 - val_loss: 0.3288\n",
      "Epoch 589/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3269 - val_loss: 0.3287\n",
      "Epoch 590/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3268 - val_loss: 0.3287\n",
      "Epoch 591/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3268 - val_loss: 0.3286\n",
      "Epoch 592/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3267 - val_loss: 0.3285\n",
      "Epoch 593/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3266 - val_loss: 0.3284\n",
      "Epoch 594/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3265 - val_loss: 0.3284\n",
      "Epoch 595/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - loss: 0.3264 - val_loss: 0.3283\n",
      "Epoch 596/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3264 - val_loss: 0.3282\n",
      "Epoch 597/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3263 - val_loss: 0.3282\n",
      "Epoch 598/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3262 - val_loss: 0.3281\n",
      "Epoch 599/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3261 - val_loss: 0.3280\n",
      "Epoch 600/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3260 - val_loss: 0.3280\n",
      "Epoch 601/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - loss: 0.3260 - val_loss: 0.3279\n",
      "Epoch 602/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3259 - val_loss: 0.3278\n",
      "Epoch 603/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3258 - val_loss: 0.3278\n",
      "Epoch 604/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3257 - val_loss: 0.3277\n",
      "Epoch 605/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3256 - val_loss: 0.3277\n",
      "Epoch 606/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3255 - val_loss: 0.3276\n",
      "Epoch 607/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3255 - val_loss: 0.3275\n",
      "Epoch 608/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3254 - val_loss: 0.3274\n",
      "Epoch 609/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3253 - val_loss: 0.3274\n",
      "Epoch 610/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3252 - val_loss: 0.3273\n",
      "Epoch 611/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3251 - val_loss: 0.3272\n",
      "Epoch 612/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3250 - val_loss: 0.3271\n",
      "Epoch 613/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3250 - val_loss: 0.3271\n",
      "Epoch 614/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - loss: 0.3249 - val_loss: 0.3270\n",
      "Epoch 615/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3248 - val_loss: 0.3269\n",
      "Epoch 616/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3247 - val_loss: 0.3269\n",
      "Epoch 617/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3246 - val_loss: 0.3267\n",
      "Epoch 618/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3245 - val_loss: 0.3267\n",
      "Epoch 619/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3245 - val_loss: 0.3266\n",
      "Epoch 620/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3244 - val_loss: 0.3266\n",
      "Epoch 621/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3243 - val_loss: 0.3264\n",
      "Epoch 622/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3242 - val_loss: 0.3264\n",
      "Epoch 623/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3241 - val_loss: 0.3263\n",
      "Epoch 624/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3240 - val_loss: 0.3262\n",
      "Epoch 625/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3239 - val_loss: 0.3262\n",
      "Epoch 626/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3239 - val_loss: 0.3261\n",
      "Epoch 627/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3238 - val_loss: 0.3260\n",
      "Epoch 628/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3237 - val_loss: 0.3259\n",
      "Epoch 629/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - loss: 0.3236 - val_loss: 0.3259\n",
      "Epoch 630/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - loss: 0.3235 - val_loss: 0.3257\n",
      "Epoch 631/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3235 - val_loss: 0.3256\n",
      "Epoch 632/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3234 - val_loss: 0.3256\n",
      "Epoch 633/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - loss: 0.3233 - val_loss: 0.3255\n",
      "Epoch 634/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3232 - val_loss: 0.3254\n",
      "Epoch 635/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - loss: 0.3231 - val_loss: 0.3254\n",
      "Epoch 636/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3231 - val_loss: 0.3252\n",
      "Epoch 637/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3230 - val_loss: 0.3252\n",
      "Epoch 638/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3229 - val_loss: 0.3251\n",
      "Epoch 639/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3228 - val_loss: 0.3250\n",
      "Epoch 640/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3227 - val_loss: 0.3250\n",
      "Epoch 641/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3227 - val_loss: 0.3249\n",
      "Epoch 642/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3226 - val_loss: 0.3248\n",
      "Epoch 643/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3225 - val_loss: 0.3248\n",
      "Epoch 644/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3224 - val_loss: 0.3247\n",
      "Epoch 645/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3224 - val_loss: 0.3246\n",
      "Epoch 646/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3223 - val_loss: 0.3245\n",
      "Epoch 647/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3222 - val_loss: 0.3244\n",
      "Epoch 648/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3221 - val_loss: 0.3243\n",
      "Epoch 649/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - loss: 0.3221 - val_loss: 0.3243\n",
      "Epoch 650/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3220 - val_loss: 0.3242\n",
      "Epoch 651/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3219 - val_loss: 0.3242\n",
      "Epoch 652/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - loss: 0.3218 - val_loss: 0.3241\n",
      "Epoch 653/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - loss: 0.3218 - val_loss: 0.3241\n",
      "Epoch 654/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3217 - val_loss: 0.3240\n",
      "Epoch 655/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3216 - val_loss: 0.3240\n",
      "Epoch 656/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3216 - val_loss: 0.3239\n",
      "Epoch 657/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3215 - val_loss: 0.3238\n",
      "Epoch 658/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - loss: 0.3214 - val_loss: 0.3238\n",
      "Epoch 659/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3214 - val_loss: 0.3237\n",
      "Epoch 660/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3213 - val_loss: 0.3236\n",
      "Epoch 661/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3212 - val_loss: 0.3236\n",
      "Epoch 662/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - loss: 0.3212 - val_loss: 0.3236\n",
      "Epoch 663/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3211 - val_loss: 0.3235\n",
      "Epoch 664/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - loss: 0.3210 - val_loss: 0.3234\n",
      "Epoch 665/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - loss: 0.3210 - val_loss: 0.3234\n",
      "Epoch 666/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - loss: 0.3209 - val_loss: 0.3233\n",
      "Epoch 667/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3208 - val_loss: 0.3232\n",
      "Epoch 668/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3207 - val_loss: 0.3232\n",
      "Epoch 669/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - loss: 0.3207 - val_loss: 0.3231\n",
      "Epoch 670/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - loss: 0.3206 - val_loss: 0.3230\n",
      "Epoch 671/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3205 - val_loss: 0.3230\n",
      "Epoch 672/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - loss: 0.3205 - val_loss: 0.3229\n",
      "Epoch 673/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3204 - val_loss: 0.3228\n",
      "Epoch 674/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - loss: 0.3203 - val_loss: 0.3228\n",
      "Epoch 675/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3202 - val_loss: 0.3227\n",
      "Epoch 676/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3201 - val_loss: 0.3226\n",
      "Epoch 677/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3201 - val_loss: 0.3226\n",
      "Epoch 678/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - loss: 0.3200 - val_loss: 0.3225\n",
      "Epoch 679/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3199 - val_loss: 0.3225\n",
      "Epoch 680/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3198 - val_loss: 0.3224\n",
      "Epoch 681/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3197 - val_loss: 0.3223\n",
      "Epoch 682/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3197 - val_loss: 0.3223\n",
      "Epoch 683/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3196 - val_loss: 0.3222\n",
      "Epoch 684/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3195 - val_loss: 0.3222\n",
      "Epoch 685/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3194 - val_loss: 0.3221\n",
      "Epoch 686/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3194 - val_loss: 0.3220\n",
      "Epoch 687/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3193 - val_loss: 0.3220\n",
      "Epoch 688/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3192 - val_loss: 0.3219\n",
      "Epoch 689/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3191 - val_loss: 0.3219\n",
      "Epoch 690/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3191 - val_loss: 0.3218\n",
      "Epoch 691/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3190 - val_loss: 0.3218\n",
      "Epoch 692/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3189 - val_loss: 0.3218\n",
      "Epoch 693/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3188 - val_loss: 0.3217\n",
      "Epoch 694/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3188 - val_loss: 0.3216\n",
      "Epoch 695/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3187 - val_loss: 0.3216\n",
      "Epoch 696/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3186 - val_loss: 0.3215\n",
      "Epoch 697/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3186 - val_loss: 0.3214\n",
      "Epoch 698/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3185 - val_loss: 0.3213\n",
      "Epoch 699/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3184 - val_loss: 0.3213\n",
      "Epoch 700/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - loss: 0.3183 - val_loss: 0.3212\n",
      "Epoch 701/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3183 - val_loss: 0.3212\n",
      "Epoch 702/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3182 - val_loss: 0.3211\n",
      "Epoch 703/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3181 - val_loss: 0.3210\n",
      "Epoch 704/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3181 - val_loss: 0.3210\n",
      "Epoch 705/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - loss: 0.3180 - val_loss: 0.3209\n",
      "Epoch 706/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3180 - val_loss: 0.3209\n",
      "Epoch 707/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3179 - val_loss: 0.3208\n",
      "Epoch 708/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3178 - val_loss: 0.3208\n",
      "Epoch 709/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3178 - val_loss: 0.3207\n",
      "Epoch 710/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3177 - val_loss: 0.3207\n",
      "Epoch 711/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3176 - val_loss: 0.3207\n",
      "Epoch 712/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3176 - val_loss: 0.3206\n",
      "Epoch 713/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3175 - val_loss: 0.3205\n",
      "Epoch 714/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3174 - val_loss: 0.3205\n",
      "Epoch 715/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3174 - val_loss: 0.3204\n",
      "Epoch 716/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3173 - val_loss: 0.3204\n",
      "Epoch 717/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3172 - val_loss: 0.3203\n",
      "Epoch 718/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3172 - val_loss: 0.3202\n",
      "Epoch 719/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3171 - val_loss: 0.3201\n",
      "Epoch 720/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3170 - val_loss: 0.3201\n",
      "Epoch 721/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - loss: 0.3169 - val_loss: 0.3200\n",
      "Epoch 722/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3169 - val_loss: 0.3200\n",
      "Epoch 723/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3168 - val_loss: 0.3199\n",
      "Epoch 724/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3167 - val_loss: 0.3199\n",
      "Epoch 725/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3167 - val_loss: 0.3199\n",
      "Epoch 726/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3166 - val_loss: 0.3198\n",
      "Epoch 727/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3165 - val_loss: 0.3198\n",
      "Epoch 728/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3165 - val_loss: 0.3197\n",
      "Epoch 729/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3164 - val_loss: 0.3196\n",
      "Epoch 730/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3163 - val_loss: 0.3196\n",
      "Epoch 731/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3163 - val_loss: 0.3196\n",
      "Epoch 732/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3162 - val_loss: 0.3195\n",
      "Epoch 733/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3161 - val_loss: 0.3195\n",
      "Epoch 734/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3161 - val_loss: 0.3194\n",
      "Epoch 735/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3160 - val_loss: 0.3193\n",
      "Epoch 736/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3159 - val_loss: 0.3193\n",
      "Epoch 737/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3159 - val_loss: 0.3192\n",
      "Epoch 738/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3158 - val_loss: 0.3191\n",
      "Epoch 739/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3157 - val_loss: 0.3191\n",
      "Epoch 740/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3157 - val_loss: 0.3190\n",
      "Epoch 741/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - loss: 0.3156 - val_loss: 0.3190\n",
      "Epoch 742/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3155 - val_loss: 0.3189\n",
      "Epoch 743/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3155 - val_loss: 0.3188\n",
      "Epoch 744/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3154 - val_loss: 0.3188\n",
      "Epoch 745/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - loss: 0.3154 - val_loss: 0.3187\n",
      "Epoch 746/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3153 - val_loss: 0.3187\n",
      "Epoch 747/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3152 - val_loss: 0.3186\n",
      "Epoch 748/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3152 - val_loss: 0.3186\n",
      "Epoch 749/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - loss: 0.3151 - val_loss: 0.3185\n",
      "Epoch 750/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3150 - val_loss: 0.3184\n",
      "Epoch 751/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - loss: 0.3150 - val_loss: 0.3184\n",
      "Epoch 752/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - loss: 0.3149 - val_loss: 0.3183\n",
      "Epoch 753/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - loss: 0.3149 - val_loss: 0.3183\n",
      "Epoch 754/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3148 - val_loss: 0.3182\n",
      "Epoch 755/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - loss: 0.3147 - val_loss: 0.3182\n",
      "Epoch 756/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - loss: 0.3147 - val_loss: 0.3181\n",
      "Epoch 757/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - loss: 0.3146 - val_loss: 0.3181\n",
      "Epoch 758/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3146 - val_loss: 0.3180\n",
      "Epoch 759/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - loss: 0.3145 - val_loss: 0.3180\n",
      "Epoch 760/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3144 - val_loss: 0.3179\n",
      "Epoch 761/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3144 - val_loss: 0.3179\n",
      "Epoch 762/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3143 - val_loss: 0.3178\n",
      "Epoch 763/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3143 - val_loss: 0.3178\n",
      "Epoch 764/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3142 - val_loss: 0.3178\n",
      "Epoch 765/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3141 - val_loss: 0.3177\n",
      "Epoch 766/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3141 - val_loss: 0.3177\n",
      "Epoch 767/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3140 - val_loss: 0.3177\n",
      "Epoch 768/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3139 - val_loss: 0.3176\n",
      "Epoch 769/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3139 - val_loss: 0.3176\n",
      "Epoch 770/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3138 - val_loss: 0.3175\n",
      "Epoch 771/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3137 - val_loss: 0.3175\n",
      "Epoch 772/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3137 - val_loss: 0.3175\n",
      "Epoch 773/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3136 - val_loss: 0.3174\n",
      "Epoch 774/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3136 - val_loss: 0.3174\n",
      "Epoch 775/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3135 - val_loss: 0.3173\n",
      "Epoch 776/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3135 - val_loss: 0.3173\n",
      "Epoch 777/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3134 - val_loss: 0.3172\n",
      "Epoch 778/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3133 - val_loss: 0.3171\n",
      "Epoch 779/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.3133 - val_loss: 0.3171\n",
      "Epoch 780/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3132 - val_loss: 0.3170\n",
      "Epoch 781/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - loss: 0.3132 - val_loss: 0.3170\n",
      "Epoch 782/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - loss: 0.3131 - val_loss: 0.3169\n",
      "Epoch 783/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3130 - val_loss: 0.3168\n",
      "Epoch 784/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - loss: 0.3130 - val_loss: 0.3168\n",
      "Epoch 785/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3129 - val_loss: 0.3167\n",
      "Epoch 786/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3128 - val_loss: 0.3167\n",
      "Epoch 787/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3127 - val_loss: 0.3166\n",
      "Epoch 788/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3127 - val_loss: 0.3165\n",
      "Epoch 789/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3126 - val_loss: 0.3165\n",
      "Epoch 790/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - loss: 0.3125 - val_loss: 0.3165\n",
      "Epoch 791/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3125 - val_loss: 0.3164\n",
      "Epoch 792/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3124 - val_loss: 0.3164\n",
      "Epoch 793/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3123 - val_loss: 0.3164\n",
      "Epoch 794/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3123 - val_loss: 0.3163\n",
      "Epoch 795/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3122 - val_loss: 0.3163\n",
      "Epoch 796/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3122 - val_loss: 0.3162\n",
      "Epoch 797/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - loss: 0.3121 - val_loss: 0.3162\n",
      "Epoch 798/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3121 - val_loss: 0.3162\n",
      "Epoch 799/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3120 - val_loss: 0.3161\n",
      "Epoch 800/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3119 - val_loss: 0.3161\n",
      "Epoch 801/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3119 - val_loss: 0.3161\n",
      "Epoch 802/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - loss: 0.3118 - val_loss: 0.3161\n",
      "Epoch 803/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - loss: 0.3118 - val_loss: 0.3160\n",
      "Epoch 804/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - loss: 0.3117 - val_loss: 0.3160\n",
      "Epoch 805/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - loss: 0.3116 - val_loss: 0.3160\n",
      "Epoch 806/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3116 - val_loss: 0.3159\n",
      "Epoch 807/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3115 - val_loss: 0.3159\n",
      "Epoch 808/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3115 - val_loss: 0.3159\n",
      "Epoch 809/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3114 - val_loss: 0.3158\n",
      "Epoch 810/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3114 - val_loss: 0.3158\n",
      "Epoch 811/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3113 - val_loss: 0.3158\n",
      "Epoch 812/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3113 - val_loss: 0.3157\n",
      "Epoch 813/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3112 - val_loss: 0.3157\n",
      "Epoch 814/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step - loss: 0.3111 - val_loss: 0.3157\n",
      "Epoch 815/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3111 - val_loss: 0.3156\n",
      "Epoch 816/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3110 - val_loss: 0.3156\n",
      "Epoch 817/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3110 - val_loss: 0.3156\n",
      "Epoch 818/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3109 - val_loss: 0.3156\n",
      "Epoch 819/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3108 - val_loss: 0.3156\n",
      "Epoch 820/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3108 - val_loss: 0.3156\n",
      "Epoch 821/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3107 - val_loss: 0.3155\n",
      "Epoch 822/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3107 - val_loss: 0.3155\n",
      "Epoch 823/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3106 - val_loss: 0.3155\n",
      "Epoch 824/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3106 - val_loss: 0.3154\n",
      "Epoch 825/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - loss: 0.3105 - val_loss: 0.3154\n",
      "Epoch 826/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3105 - val_loss: 0.3154\n",
      "Epoch 827/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3104 - val_loss: 0.3153\n",
      "Epoch 828/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3104 - val_loss: 0.3153\n",
      "Epoch 829/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3103 - val_loss: 0.3153\n",
      "Epoch 830/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3103 - val_loss: 0.3152\n",
      "Epoch 831/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3102 - val_loss: 0.3152\n",
      "Epoch 832/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3101 - val_loss: 0.3152\n",
      "Epoch 833/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3101 - val_loss: 0.3152\n",
      "Epoch 834/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3100 - val_loss: 0.3151\n",
      "Epoch 835/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3099 - val_loss: 0.3151\n",
      "Epoch 836/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - loss: 0.3099 - val_loss: 0.3151\n",
      "Epoch 837/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3098 - val_loss: 0.3151\n",
      "Epoch 838/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3098 - val_loss: 0.3150\n",
      "Epoch 839/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3097 - val_loss: 0.3149\n",
      "Epoch 840/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3097 - val_loss: 0.3149\n",
      "Epoch 841/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3096 - val_loss: 0.3149\n",
      "Epoch 842/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3096 - val_loss: 0.3148\n",
      "Epoch 843/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3095 - val_loss: 0.3148\n",
      "Epoch 844/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3095 - val_loss: 0.3147\n",
      "Epoch 845/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3094 - val_loss: 0.3147\n",
      "Epoch 846/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3094 - val_loss: 0.3147\n",
      "Epoch 847/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3093 - val_loss: 0.3146\n",
      "Epoch 848/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - loss: 0.3093 - val_loss: 0.3146\n",
      "Epoch 849/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - loss: 0.3092 - val_loss: 0.3146\n",
      "Epoch 850/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3092 - val_loss: 0.3145\n",
      "Epoch 851/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3091 - val_loss: 0.3145\n",
      "Epoch 852/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3091 - val_loss: 0.3144\n",
      "Epoch 853/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3090 - val_loss: 0.3144\n",
      "Epoch 854/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3090 - val_loss: 0.3144\n",
      "Epoch 855/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3089 - val_loss: 0.3143\n",
      "Epoch 856/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3089 - val_loss: 0.3143\n",
      "Epoch 857/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3088 - val_loss: 0.3143\n",
      "Epoch 858/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3088 - val_loss: 0.3143\n",
      "Epoch 859/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3087 - val_loss: 0.3142\n",
      "Epoch 860/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3087 - val_loss: 0.3142\n",
      "Epoch 861/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3086 - val_loss: 0.3142\n",
      "Epoch 862/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3086 - val_loss: 0.3141\n",
      "Epoch 863/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3086 - val_loss: 0.3141\n",
      "Epoch 864/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3085 - val_loss: 0.3141\n",
      "Epoch 865/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3085 - val_loss: 0.3141\n",
      "Epoch 866/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3084 - val_loss: 0.3140\n",
      "Epoch 867/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3084 - val_loss: 0.3140\n",
      "Epoch 868/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3083 - val_loss: 0.3140\n",
      "Epoch 869/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3083 - val_loss: 0.3140\n",
      "Epoch 870/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3083 - val_loss: 0.3140\n",
      "Epoch 871/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3082 - val_loss: 0.3140\n",
      "Epoch 872/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3082 - val_loss: 0.3140\n",
      "Epoch 873/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3081 - val_loss: 0.3139\n",
      "Epoch 874/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3081 - val_loss: 0.3139\n",
      "Epoch 875/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3080 - val_loss: 0.3139\n",
      "Epoch 876/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3080 - val_loss: 0.3138\n",
      "Epoch 877/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3079 - val_loss: 0.3138\n",
      "Epoch 878/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3079 - val_loss: 0.3138\n",
      "Epoch 879/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3079 - val_loss: 0.3137\n",
      "Epoch 880/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - loss: 0.3078 - val_loss: 0.3137\n",
      "Epoch 881/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3078 - val_loss: 0.3137\n",
      "Epoch 882/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3077 - val_loss: 0.3136\n",
      "Epoch 883/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3077 - val_loss: 0.3136\n",
      "Epoch 884/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3077 - val_loss: 0.3136\n",
      "Epoch 885/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3076 - val_loss: 0.3136\n",
      "Epoch 886/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3076 - val_loss: 0.3135\n",
      "Epoch 887/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3075 - val_loss: 0.3135\n",
      "Epoch 888/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3075 - val_loss: 0.3135\n",
      "Epoch 889/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3074 - val_loss: 0.3135\n",
      "Epoch 890/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3074 - val_loss: 0.3134\n",
      "Epoch 891/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3074 - val_loss: 0.3134\n",
      "Epoch 892/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3073 - val_loss: 0.3134\n",
      "Epoch 893/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3073 - val_loss: 0.3134\n",
      "Epoch 894/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3072 - val_loss: 0.3133\n",
      "Epoch 895/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3072 - val_loss: 0.3133\n",
      "Epoch 896/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3071 - val_loss: 0.3133\n",
      "Epoch 897/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3071 - val_loss: 0.3133\n",
      "Epoch 898/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3070 - val_loss: 0.3133\n",
      "Epoch 899/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3070 - val_loss: 0.3133\n",
      "Epoch 900/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3070 - val_loss: 0.3133\n",
      "Epoch 901/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3069 - val_loss: 0.3132\n",
      "Epoch 902/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3069 - val_loss: 0.3132\n",
      "Epoch 903/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3068 - val_loss: 0.3132\n",
      "Epoch 904/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3068 - val_loss: 0.3132\n",
      "Epoch 905/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3067 - val_loss: 0.3132\n",
      "Epoch 906/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3067 - val_loss: 0.3132\n",
      "Epoch 907/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3067 - val_loss: 0.3132\n",
      "Epoch 908/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3066 - val_loss: 0.3131\n",
      "Epoch 909/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3066 - val_loss: 0.3131\n",
      "Epoch 910/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3065 - val_loss: 0.3131\n",
      "Epoch 911/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3065 - val_loss: 0.3131\n",
      "Epoch 912/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3065 - val_loss: 0.3130\n",
      "Epoch 913/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3064 - val_loss: 0.3130\n",
      "Epoch 914/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - loss: 0.3064 - val_loss: 0.3130\n",
      "Epoch 915/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3064 - val_loss: 0.3130\n",
      "Epoch 916/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3063 - val_loss: 0.3130\n",
      "Epoch 917/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3063 - val_loss: 0.3130\n",
      "Epoch 918/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3063 - val_loss: 0.3130\n",
      "Epoch 919/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3062 - val_loss: 0.3129\n",
      "Epoch 920/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3062 - val_loss: 0.3129\n",
      "Epoch 921/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3061 - val_loss: 0.3129\n",
      "Epoch 922/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3061 - val_loss: 0.3129\n",
      "Epoch 923/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3061 - val_loss: 0.3129\n",
      "Epoch 924/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3060 - val_loss: 0.3128\n",
      "Epoch 925/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3060 - val_loss: 0.3128\n",
      "Epoch 926/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3060 - val_loss: 0.3128\n",
      "Epoch 927/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3059 - val_loss: 0.3128\n",
      "Epoch 928/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - loss: 0.3059 - val_loss: 0.3128\n",
      "Epoch 929/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3059 - val_loss: 0.3127\n",
      "Epoch 930/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3058 - val_loss: 0.3127\n",
      "Epoch 931/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3058 - val_loss: 0.3127\n",
      "Epoch 932/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3058 - val_loss: 0.3127\n",
      "Epoch 933/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - loss: 0.3057 - val_loss: 0.3126\n",
      "Epoch 934/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3057 - val_loss: 0.3126\n",
      "Epoch 935/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3056 - val_loss: 0.3126\n",
      "Epoch 936/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3056 - val_loss: 0.3126\n",
      "Epoch 937/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3056 - val_loss: 0.3126\n",
      "Epoch 938/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3055 - val_loss: 0.3126\n",
      "Epoch 939/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3055 - val_loss: 0.3125\n",
      "Epoch 940/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3054 - val_loss: 0.3125\n",
      "Epoch 941/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3054 - val_loss: 0.3125\n",
      "Epoch 942/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3054 - val_loss: 0.3124\n",
      "Epoch 943/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3053 - val_loss: 0.3124\n",
      "Epoch 944/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3053 - val_loss: 0.3124\n",
      "Epoch 945/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3053 - val_loss: 0.3124\n",
      "Epoch 946/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3052 - val_loss: 0.3124\n",
      "Epoch 947/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3052 - val_loss: 0.3123\n",
      "Epoch 948/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3052 - val_loss: 0.3123\n",
      "Epoch 949/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3051 - val_loss: 0.3123\n",
      "Epoch 950/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3051 - val_loss: 0.3123\n",
      "Epoch 951/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3051 - val_loss: 0.3123\n",
      "Epoch 952/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - loss: 0.3050 - val_loss: 0.3122\n",
      "Epoch 953/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3050 - val_loss: 0.3122\n",
      "Epoch 954/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3050 - val_loss: 0.3122\n",
      "Epoch 955/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3049 - val_loss: 0.3122\n",
      "Epoch 956/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3049 - val_loss: 0.3121\n",
      "Epoch 957/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3049 - val_loss: 0.3121\n",
      "Epoch 958/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3049 - val_loss: 0.3121\n",
      "Epoch 959/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3048 - val_loss: 0.3120\n",
      "Epoch 960/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3048 - val_loss: 0.3120\n",
      "Epoch 961/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3047 - val_loss: 0.3120\n",
      "Epoch 962/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3047 - val_loss: 0.3120\n",
      "Epoch 963/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3047 - val_loss: 0.3119\n",
      "Epoch 964/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3047 - val_loss: 0.3119\n",
      "Epoch 965/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3046 - val_loss: 0.3119\n",
      "Epoch 966/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3046 - val_loss: 0.3119\n",
      "Epoch 967/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3046 - val_loss: 0.3119\n",
      "Epoch 968/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3045 - val_loss: 0.3118\n",
      "Epoch 969/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - loss: 0.3045 - val_loss: 0.3118\n",
      "Epoch 970/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - loss: 0.3045 - val_loss: 0.3118\n",
      "Epoch 971/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - loss: 0.3044 - val_loss: 0.3118\n",
      "Epoch 972/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3044 - val_loss: 0.3117\n",
      "Epoch 973/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - loss: 0.3044 - val_loss: 0.3117\n",
      "Epoch 974/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - loss: 0.3043 - val_loss: 0.3117\n",
      "Epoch 975/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3043 - val_loss: 0.3117\n",
      "Epoch 976/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3043 - val_loss: 0.3116\n",
      "Epoch 977/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - loss: 0.3042 - val_loss: 0.3116\n",
      "Epoch 978/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3042 - val_loss: 0.3116\n",
      "Epoch 979/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3042 - val_loss: 0.3116\n",
      "Epoch 980/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3041 - val_loss: 0.3116\n",
      "Epoch 981/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3041 - val_loss: 0.3115\n",
      "Epoch 982/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3041 - val_loss: 0.3116\n",
      "Epoch 983/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3041 - val_loss: 0.3115\n",
      "Epoch 984/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3040 - val_loss: 0.3115\n",
      "Epoch 985/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3040 - val_loss: 0.3115\n",
      "Epoch 986/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3040 - val_loss: 0.3114\n",
      "Epoch 987/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3039 - val_loss: 0.3114\n",
      "Epoch 988/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3039 - val_loss: 0.3114\n",
      "Epoch 989/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3039 - val_loss: 0.3114\n",
      "Epoch 990/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3038 - val_loss: 0.3114\n",
      "Epoch 991/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - loss: 0.3038 - val_loss: 0.3114\n",
      "Epoch 992/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - loss: 0.3038 - val_loss: 0.3113\n",
      "Epoch 993/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - loss: 0.3038 - val_loss: 0.3113\n",
      "Epoch 994/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3037 - val_loss: 0.3113\n",
      "Epoch 995/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - loss: 0.3037 - val_loss: 0.3112\n",
      "Epoch 996/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - loss: 0.3037 - val_loss: 0.3112\n",
      "Epoch 997/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - loss: 0.3037 - val_loss: 0.3112\n",
      "Epoch 998/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - loss: 0.3036 - val_loss: 0.3112\n",
      "Epoch 999/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - loss: 0.3036 - val_loss: 0.3111\n",
      "Epoch 1000/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3036 - val_loss: 0.3111\n",
      "Epoch 1001/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - loss: 0.3035 - val_loss: 0.3111\n",
      "Epoch 1002/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - loss: 0.3035 - val_loss: 0.3111\n",
      "Epoch 1003/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - loss: 0.3035 - val_loss: 0.3111\n",
      "Epoch 1004/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3035 - val_loss: 0.3110\n",
      "Epoch 1005/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3034 - val_loss: 0.3110\n",
      "Epoch 1006/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3034 - val_loss: 0.3110\n",
      "Epoch 1007/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3034 - val_loss: 0.3110\n",
      "Epoch 1008/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3034 - val_loss: 0.3109\n",
      "Epoch 1009/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3033 - val_loss: 0.3109\n",
      "Epoch 1010/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3033 - val_loss: 0.3109\n",
      "Epoch 1011/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3033 - val_loss: 0.3109\n",
      "Epoch 1012/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - loss: 0.3032 - val_loss: 0.3108\n",
      "Epoch 1013/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3032 - val_loss: 0.3109\n",
      "Epoch 1014/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - loss: 0.3032 - val_loss: 0.3108\n",
      "Epoch 1015/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - loss: 0.3031 - val_loss: 0.3108\n",
      "Epoch 1016/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3031 - val_loss: 0.3108\n",
      "Epoch 1017/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - loss: 0.3031 - val_loss: 0.3108\n",
      "Epoch 1018/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - loss: 0.3030 - val_loss: 0.3107\n",
      "Epoch 1019/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3030 - val_loss: 0.3107\n",
      "Epoch 1020/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - loss: 0.3030 - val_loss: 0.3107\n",
      "Epoch 1021/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - loss: 0.3030 - val_loss: 0.3107\n",
      "Epoch 1022/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3029 - val_loss: 0.3106\n",
      "Epoch 1023/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3029 - val_loss: 0.3107\n",
      "Epoch 1024/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - loss: 0.3029 - val_loss: 0.3106\n",
      "Epoch 1025/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3028 - val_loss: 0.3106\n",
      "Epoch 1026/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - loss: 0.3028 - val_loss: 0.3106\n",
      "Epoch 1027/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - loss: 0.3028 - val_loss: 0.3106\n",
      "Epoch 1028/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3028 - val_loss: 0.3105\n",
      "Epoch 1029/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - loss: 0.3027 - val_loss: 0.3105\n",
      "Epoch 1030/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - loss: 0.3027 - val_loss: 0.3105\n",
      "Epoch 1031/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3027 - val_loss: 0.3105\n",
      "Epoch 1032/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - loss: 0.3027 - val_loss: 0.3105\n",
      "Epoch 1033/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - loss: 0.3027 - val_loss: 0.3104\n",
      "Epoch 1034/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3026 - val_loss: 0.3104\n",
      "Epoch 1035/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - loss: 0.3026 - val_loss: 0.3104\n",
      "Epoch 1036/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - loss: 0.3026 - val_loss: 0.3104\n",
      "Epoch 1037/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3026 - val_loss: 0.3104\n",
      "Epoch 1038/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - loss: 0.3025 - val_loss: 0.3104\n",
      "Epoch 1039/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3025 - val_loss: 0.3103\n",
      "Epoch 1040/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3025 - val_loss: 0.3103\n",
      "Epoch 1041/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3024 - val_loss: 0.3103\n",
      "Epoch 1042/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3024 - val_loss: 0.3102\n",
      "Epoch 1043/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3024 - val_loss: 0.3102\n",
      "Epoch 1044/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - loss: 0.3024 - val_loss: 0.3102\n",
      "Epoch 1045/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - loss: 0.3023 - val_loss: 0.3102\n",
      "Epoch 1046/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3023 - val_loss: 0.3102\n",
      "Epoch 1047/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3023 - val_loss: 0.3101\n",
      "Epoch 1048/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - loss: 0.3022 - val_loss: 0.3101\n",
      "Epoch 1049/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3022 - val_loss: 0.3101\n",
      "Epoch 1050/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3022 - val_loss: 0.3101\n",
      "Epoch 1051/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3022 - val_loss: 0.3100\n",
      "Epoch 1052/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3021 - val_loss: 0.3100\n",
      "Epoch 1053/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3021 - val_loss: 0.3100\n",
      "Epoch 1054/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3021 - val_loss: 0.3100\n",
      "Epoch 1055/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3020 - val_loss: 0.3100\n",
      "Epoch 1056/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3020 - val_loss: 0.3099\n",
      "Epoch 1057/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3020 - val_loss: 0.3099\n",
      "Epoch 1058/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3019 - val_loss: 0.3099\n",
      "Epoch 1059/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3019 - val_loss: 0.3099\n",
      "Epoch 1060/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3019 - val_loss: 0.3099\n",
      "Epoch 1061/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3019 - val_loss: 0.3098\n",
      "Epoch 1062/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step - loss: 0.3019 - val_loss: 0.3098\n",
      "Epoch 1063/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3018 - val_loss: 0.3098\n",
      "Epoch 1064/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3018 - val_loss: 0.3098\n",
      "Epoch 1065/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3018 - val_loss: 0.3098\n",
      "Epoch 1066/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3017 - val_loss: 0.3098\n",
      "Epoch 1067/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3017 - val_loss: 0.3097\n",
      "Epoch 1068/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3017 - val_loss: 0.3097\n",
      "Epoch 1069/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3017 - val_loss: 0.3097\n",
      "Epoch 1070/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3016 - val_loss: 0.3097\n",
      "Epoch 1071/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3016 - val_loss: 0.3097\n",
      "Epoch 1072/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3016 - val_loss: 0.3097\n",
      "Epoch 1073/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3016 - val_loss: 0.3096\n",
      "Epoch 1074/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3015 - val_loss: 0.3096\n",
      "Epoch 1075/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3015 - val_loss: 0.3096\n",
      "Epoch 1076/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3015 - val_loss: 0.3096\n",
      "Epoch 1077/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3015 - val_loss: 0.3096\n",
      "Epoch 1078/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3014 - val_loss: 0.3095\n",
      "Epoch 1079/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3014 - val_loss: 0.3095\n",
      "Epoch 1080/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3014 - val_loss: 0.3095\n",
      "Epoch 1081/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3014 - val_loss: 0.3095\n",
      "Epoch 1082/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3013 - val_loss: 0.3094\n",
      "Epoch 1083/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3013 - val_loss: 0.3094\n",
      "Epoch 1084/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3013 - val_loss: 0.3094\n",
      "Epoch 1085/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3013 - val_loss: 0.3093\n",
      "Epoch 1086/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3012 - val_loss: 0.3093\n",
      "Epoch 1087/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3012 - val_loss: 0.3093\n",
      "Epoch 1088/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3012 - val_loss: 0.3093\n",
      "Epoch 1089/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3012 - val_loss: 0.3092\n",
      "Epoch 1090/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3012 - val_loss: 0.3092\n",
      "Epoch 1091/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3011 - val_loss: 0.3092\n",
      "Epoch 1092/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3011 - val_loss: 0.3091\n",
      "Epoch 1093/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3011 - val_loss: 0.3091\n",
      "Epoch 1094/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3011 - val_loss: 0.3091\n",
      "Epoch 1095/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3010 - val_loss: 0.3091\n",
      "Epoch 1096/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3010 - val_loss: 0.3091\n",
      "Epoch 1097/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3010 - val_loss: 0.3090\n",
      "Epoch 1098/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3010 - val_loss: 0.3090\n",
      "Epoch 1099/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3009 - val_loss: 0.3090\n",
      "Epoch 1100/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3009 - val_loss: 0.3090\n",
      "Epoch 1101/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3009 - val_loss: 0.3089\n",
      "Epoch 1102/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3009 - val_loss: 0.3089\n",
      "Epoch 1103/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3008 - val_loss: 0.3089\n",
      "Epoch 1104/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3008 - val_loss: 0.3089\n",
      "Epoch 1105/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3008 - val_loss: 0.3089\n",
      "Epoch 1106/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3008 - val_loss: 0.3089\n",
      "Epoch 1107/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3007 - val_loss: 0.3089\n",
      "Epoch 1108/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3007 - val_loss: 0.3088\n",
      "Epoch 1109/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3007 - val_loss: 0.3088\n",
      "Epoch 1110/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3007 - val_loss: 0.3088\n",
      "Epoch 1111/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3007 - val_loss: 0.3088\n",
      "Epoch 1112/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3006 - val_loss: 0.3088\n",
      "Epoch 1113/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3006 - val_loss: 0.3088\n",
      "Epoch 1114/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3006 - val_loss: 0.3087\n",
      "Epoch 1115/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3006 - val_loss: 0.3087\n",
      "Epoch 1116/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3005 - val_loss: 0.3087\n",
      "Epoch 1117/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3005 - val_loss: 0.3087\n",
      "Epoch 1118/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3005 - val_loss: 0.3086\n",
      "Epoch 1119/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3005 - val_loss: 0.3086\n",
      "Epoch 1120/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3004 - val_loss: 0.3086\n",
      "Epoch 1121/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3004 - val_loss: 0.3086\n",
      "Epoch 1122/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3004 - val_loss: 0.3086\n",
      "Epoch 1123/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3004 - val_loss: 0.3085\n",
      "Epoch 1124/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3003 - val_loss: 0.3085\n",
      "Epoch 1125/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3003 - val_loss: 0.3085\n",
      "Epoch 1126/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3003 - val_loss: 0.3085\n",
      "Epoch 1127/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3003 - val_loss: 0.3085\n",
      "Epoch 1128/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3002 - val_loss: 0.3085\n",
      "Epoch 1129/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3002 - val_loss: 0.3085\n",
      "Epoch 1130/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3002 - val_loss: 0.3085\n",
      "Epoch 1131/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3002 - val_loss: 0.3084\n",
      "Epoch 1132/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3002 - val_loss: 0.3084\n",
      "Epoch 1133/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3001 - val_loss: 0.3084\n",
      "Epoch 1134/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3001 - val_loss: 0.3084\n",
      "Epoch 1135/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3001 - val_loss: 0.3084\n",
      "Epoch 1136/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3001 - val_loss: 0.3084\n",
      "Epoch 1137/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3000 - val_loss: 0.3084\n",
      "Epoch 1138/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3000 - val_loss: 0.3084\n",
      "Epoch 1139/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3000 - val_loss: 0.3084\n",
      "Epoch 1140/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3000 - val_loss: 0.3084\n",
      "Epoch 1141/10000\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2999 - val_loss: 0.3084\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"model/my_keras_model.keras\", save_best_only=True)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10000,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.0501420497894287,\n",
       " 0.8397325277328491,\n",
       " 0.7408866882324219,\n",
       " 0.6940593719482422,\n",
       " 0.6573376655578613,\n",
       " 0.6268030405044556,\n",
       " 0.6007121801376343,\n",
       " 0.5785885453224182,\n",
       " 0.5598815083503723,\n",
       " 0.544056236743927,\n",
       " 0.5306870937347412,\n",
       " 0.5194090008735657,\n",
       " 0.5098521113395691,\n",
       " 0.5016854405403137,\n",
       " 0.4947471618652344,\n",
       " 0.48890188336372375,\n",
       " 0.4839125871658325,\n",
       " 0.4795832931995392,\n",
       " 0.4758329689502716,\n",
       " 0.47256216406822205,\n",
       " 0.46963369846343994,\n",
       " 0.46700072288513184,\n",
       " 0.4645691514015198,\n",
       " 0.46232110261917114,\n",
       " 0.4602140486240387,\n",
       " 0.45824113488197327,\n",
       " 0.4563668370246887,\n",
       " 0.4545576572418213,\n",
       " 0.45282697677612305,\n",
       " 0.45117446780204773,\n",
       " 0.4495824873447418,\n",
       " 0.4480511248111725,\n",
       " 0.44656461477279663,\n",
       " 0.4451341927051544,\n",
       " 0.4437750279903412,\n",
       " 0.44247445464134216,\n",
       " 0.4412166476249695,\n",
       " 0.43998610973358154,\n",
       " 0.43879222869873047,\n",
       " 0.43763652443885803,\n",
       " 0.43651118874549866,\n",
       " 0.43540993332862854,\n",
       " 0.4343356490135193,\n",
       " 0.4332730174064636,\n",
       " 0.4322095215320587,\n",
       " 0.43115702271461487,\n",
       " 0.43008720874786377,\n",
       " 0.4290248453617096,\n",
       " 0.42800503969192505,\n",
       " 0.4270145297050476,\n",
       " 0.4260547161102295,\n",
       " 0.4251275062561035,\n",
       " 0.4242284595966339,\n",
       " 0.42332467436790466,\n",
       " 0.42245975136756897,\n",
       " 0.4216451942920685,\n",
       " 0.4208584725856781,\n",
       " 0.42009472846984863,\n",
       " 0.41934868693351746,\n",
       " 0.41861000657081604,\n",
       " 0.4178926348686218,\n",
       " 0.41720348596572876,\n",
       " 0.4165286421775818,\n",
       " 0.4158705770969391,\n",
       " 0.4152204096317291,\n",
       " 0.4145795404911041,\n",
       " 0.4139457643032074,\n",
       " 0.41331321001052856,\n",
       " 0.4126879870891571,\n",
       " 0.4120789170265198,\n",
       " 0.41146785020828247,\n",
       " 0.41086676716804504,\n",
       " 0.4102749824523926,\n",
       " 0.40968891978263855,\n",
       " 0.40911319851875305,\n",
       " 0.40854597091674805,\n",
       " 0.4079892933368683,\n",
       " 0.4074379801750183,\n",
       " 0.40688517689704895,\n",
       " 0.4063366651535034,\n",
       " 0.4057875871658325,\n",
       " 0.40524736046791077,\n",
       " 0.4047102630138397,\n",
       " 0.40417468547821045,\n",
       " 0.40364667773246765,\n",
       " 0.4031199812889099,\n",
       " 0.4025980234146118,\n",
       " 0.40207844972610474,\n",
       " 0.40157848596572876,\n",
       " 0.4010847210884094,\n",
       " 0.40059566497802734,\n",
       " 0.40010330080986023,\n",
       " 0.3996134102344513,\n",
       " 0.399114191532135,\n",
       " 0.3986143171787262,\n",
       " 0.39811161160469055,\n",
       " 0.3976101875305176,\n",
       " 0.3971010446548462,\n",
       " 0.3965636193752289,\n",
       " 0.39602893590927124,\n",
       " 0.3955058455467224,\n",
       " 0.3950030505657196,\n",
       " 0.3944946527481079,\n",
       " 0.39397192001342773,\n",
       " 0.3934628367424011,\n",
       " 0.39297837018966675,\n",
       " 0.3925072252750397,\n",
       " 0.39203137159347534,\n",
       " 0.39156675338745117,\n",
       " 0.39110028743743896,\n",
       " 0.39063096046447754,\n",
       " 0.3901740312576294,\n",
       " 0.3897263705730438,\n",
       " 0.3892801105976105,\n",
       " 0.38884368538856506,\n",
       " 0.38841208815574646,\n",
       " 0.3879890739917755,\n",
       " 0.38756754994392395,\n",
       " 0.38714948296546936,\n",
       " 0.3867323398590088,\n",
       " 0.38632822036743164,\n",
       " 0.3859245777130127,\n",
       " 0.3855290412902832,\n",
       " 0.3851388096809387,\n",
       " 0.3847501575946808,\n",
       " 0.38436850905418396,\n",
       " 0.38399502635002136,\n",
       " 0.38362714648246765,\n",
       " 0.3832660913467407,\n",
       " 0.38290396332740784,\n",
       " 0.38254913687705994,\n",
       " 0.38219955563545227,\n",
       " 0.38184863328933716,\n",
       " 0.38149797916412354,\n",
       " 0.3811553716659546,\n",
       " 0.3808213174343109,\n",
       " 0.38049420714378357,\n",
       " 0.38017064332962036,\n",
       " 0.3798569440841675,\n",
       " 0.3795517385005951,\n",
       " 0.37923142313957214,\n",
       " 0.37891271710395813,\n",
       " 0.37859442830085754,\n",
       " 0.3782773017883301,\n",
       " 0.37796199321746826,\n",
       " 0.3776489496231079,\n",
       " 0.37733715772628784,\n",
       " 0.37702861428260803,\n",
       " 0.37672093510627747,\n",
       " 0.37641286849975586,\n",
       " 0.3761081099510193,\n",
       " 0.3758002519607544,\n",
       " 0.375499963760376,\n",
       " 0.37520772218704224,\n",
       " 0.37491440773010254,\n",
       " 0.3746216595172882,\n",
       " 0.3743342459201813,\n",
       " 0.37404876947402954,\n",
       " 0.37376248836517334,\n",
       " 0.3734838366508484,\n",
       " 0.37320366501808167,\n",
       " 0.37293118238449097,\n",
       " 0.3726596236228943,\n",
       " 0.3723979890346527,\n",
       " 0.3721354901790619,\n",
       " 0.37187692523002625,\n",
       " 0.37162670493125916,\n",
       " 0.37138092517852783,\n",
       " 0.37113362550735474,\n",
       " 0.3708840608596802,\n",
       " 0.37063440680503845,\n",
       " 0.3703921139240265,\n",
       " 0.37015029788017273,\n",
       " 0.36990687251091003,\n",
       " 0.36966466903686523,\n",
       " 0.3694264888763428,\n",
       " 0.3691888153553009,\n",
       " 0.3689509630203247,\n",
       " 0.3687063753604889,\n",
       " 0.36846792697906494,\n",
       " 0.36823025345802307,\n",
       " 0.36799100041389465,\n",
       " 0.36774441599845886,\n",
       " 0.36750170588493347,\n",
       " 0.3672631084918976,\n",
       " 0.36702415347099304,\n",
       " 0.3667830526828766,\n",
       " 0.3665437400341034,\n",
       " 0.366308331489563,\n",
       " 0.3660735785961151,\n",
       " 0.36584416031837463,\n",
       " 0.3656144440174103,\n",
       " 0.36538568139076233,\n",
       " 0.3651595413684845,\n",
       " 0.36493879556655884,\n",
       " 0.364717572927475,\n",
       " 0.36449605226516724,\n",
       " 0.3642846941947937,\n",
       " 0.36407214403152466,\n",
       " 0.3638615608215332,\n",
       " 0.36366337537765503,\n",
       " 0.363463431596756,\n",
       " 0.3632667064666748,\n",
       " 0.36306583881378174,\n",
       " 0.3628723621368408,\n",
       " 0.3626762926578522,\n",
       " 0.36248093843460083,\n",
       " 0.36228957772254944,\n",
       " 0.3620956540107727,\n",
       " 0.3619038760662079,\n",
       " 0.3617222309112549,\n",
       " 0.3615345060825348,\n",
       " 0.3613491952419281,\n",
       " 0.36116519570350647,\n",
       " 0.3609892427921295,\n",
       " 0.3608101010322571,\n",
       " 0.36063051223754883,\n",
       " 0.36045730113983154,\n",
       " 0.36027923226356506,\n",
       " 0.3601056635379791,\n",
       " 0.3599366843700409,\n",
       " 0.35976436734199524,\n",
       " 0.3595934510231018,\n",
       " 0.3594256639480591,\n",
       " 0.35925567150115967,\n",
       " 0.3590874671936035,\n",
       " 0.35892361402511597,\n",
       " 0.358754962682724,\n",
       " 0.35859215259552,\n",
       " 0.35842084884643555,\n",
       " 0.35825759172439575,\n",
       " 0.3580893576145172,\n",
       " 0.35792768001556396,\n",
       " 0.35776060819625854,\n",
       " 0.35760608315467834,\n",
       " 0.3574443757534027,\n",
       " 0.3572927713394165,\n",
       " 0.35713303089141846,\n",
       " 0.3569805324077606,\n",
       " 0.3568291962146759,\n",
       " 0.3566758632659912,\n",
       " 0.3565271496772766,\n",
       " 0.3563731908798218,\n",
       " 0.3562246263027191,\n",
       " 0.3560725748538971,\n",
       " 0.3559246361255646,\n",
       " 0.3557748794555664,\n",
       " 0.3556300103664398,\n",
       " 0.3554794192314148,\n",
       " 0.35533779859542847,\n",
       " 0.35518836975097656,\n",
       " 0.35504695773124695,\n",
       " 0.3549003005027771,\n",
       " 0.35476166009902954,\n",
       " 0.3546196520328522,\n",
       " 0.3544812798500061,\n",
       " 0.35434141755104065,\n",
       " 0.35421040654182434,\n",
       " 0.3540722131729126,\n",
       " 0.3539440929889679,\n",
       " 0.35380879044532776,\n",
       " 0.3536809980869293,\n",
       " 0.35354241728782654,\n",
       " 0.3534125089645386,\n",
       " 0.3532770276069641,\n",
       " 0.35314905643463135,\n",
       " 0.3530184328556061,\n",
       " 0.3528946042060852,\n",
       " 0.3527655601501465,\n",
       " 0.3526380956172943,\n",
       " 0.352518767118454,\n",
       " 0.35239091515541077,\n",
       " 0.35226625204086304,\n",
       " 0.35214561223983765,\n",
       " 0.3520168364048004,\n",
       " 0.3518981635570526,\n",
       " 0.35177212953567505,\n",
       " 0.3516504168510437,\n",
       " 0.35152578353881836,\n",
       " 0.35140877962112427,\n",
       " 0.3512866795063019,\n",
       " 0.3511631488800049,\n",
       " 0.35104331374168396,\n",
       " 0.35091981291770935,\n",
       " 0.3508039116859436,\n",
       " 0.3506811261177063,\n",
       " 0.35056453943252563,\n",
       " 0.35044217109680176,\n",
       " 0.3503272533416748,\n",
       " 0.35020798444747925,\n",
       " 0.35009023547172546,\n",
       " 0.34997475147247314,\n",
       " 0.34985536336898804,\n",
       " 0.34974345564842224,\n",
       " 0.3496229946613312,\n",
       " 0.34950390458106995,\n",
       " 0.34938541054725647,\n",
       " 0.34926772117614746,\n",
       " 0.34915366768836975,\n",
       " 0.34903427958488464,\n",
       " 0.34891563653945923,\n",
       " 0.34880349040031433,\n",
       " 0.34868964552879333,\n",
       " 0.3485754132270813,\n",
       " 0.34845760464668274,\n",
       " 0.34834977984428406,\n",
       " 0.3482348620891571,\n",
       " 0.34811505675315857,\n",
       " 0.3479953408241272,\n",
       " 0.3478841483592987,\n",
       " 0.34776848554611206,\n",
       " 0.34765133261680603,\n",
       " 0.3475362956523895,\n",
       " 0.34742471575737,\n",
       " 0.34731414914131165,\n",
       " 0.3471982181072235,\n",
       " 0.34709131717681885,\n",
       " 0.34697389602661133,\n",
       " 0.34685996174812317,\n",
       " 0.3467472493648529,\n",
       " 0.3466433882713318,\n",
       " 0.34653350710868835,\n",
       " 0.34642478823661804,\n",
       " 0.34631165862083435,\n",
       " 0.34620484709739685,\n",
       " 0.34608957171440125,\n",
       " 0.34597593545913696,\n",
       " 0.34586644172668457,\n",
       " 0.34576043486595154,\n",
       " 0.3456461727619171,\n",
       " 0.34553924202919006,\n",
       " 0.34543684124946594,\n",
       " 0.34533122181892395,\n",
       " 0.34522688388824463,\n",
       " 0.3451205790042877,\n",
       " 0.3450222611427307,\n",
       " 0.34491902589797974,\n",
       " 0.34481796622276306,\n",
       " 0.3447154462337494,\n",
       " 0.344618022441864,\n",
       " 0.344517320394516,\n",
       " 0.3444121778011322,\n",
       " 0.34431779384613037,\n",
       " 0.34421291947364807,\n",
       " 0.34411320090293884,\n",
       " 0.34401947259902954,\n",
       " 0.34391191601753235,\n",
       " 0.3438054621219635,\n",
       " 0.34370556473731995,\n",
       " 0.34359297156333923,\n",
       " 0.34348052740097046,\n",
       " 0.3433772027492523,\n",
       " 0.34327033162117004,\n",
       " 0.343160480260849,\n",
       " 0.34305626153945923,\n",
       " 0.3429490029811859,\n",
       " 0.34284308552742004,\n",
       " 0.34273454546928406,\n",
       " 0.3426342010498047,\n",
       " 0.3425237536430359,\n",
       " 0.34241610765457153,\n",
       " 0.34231340885162354,\n",
       " 0.34220215678215027,\n",
       " 0.34209027886390686,\n",
       " 0.3419850170612335,\n",
       " 0.34187620878219604,\n",
       " 0.341762900352478,\n",
       " 0.3416459262371063,\n",
       " 0.3415379524230957,\n",
       " 0.3414199948310852,\n",
       " 0.34130966663360596,\n",
       " 0.34119728207588196,\n",
       " 0.34107890725135803,\n",
       " 0.3409615159034729,\n",
       " 0.34084540605545044,\n",
       " 0.34072762727737427,\n",
       " 0.3406114876270294,\n",
       " 0.340496301651001,\n",
       " 0.3403816521167755,\n",
       " 0.34025877714157104,\n",
       " 0.34014225006103516,\n",
       " 0.3400209844112396,\n",
       " 0.3398977518081665,\n",
       " 0.3397817015647888,\n",
       " 0.33966413140296936,\n",
       " 0.33954188227653503,\n",
       " 0.33942484855651855,\n",
       " 0.33930322527885437,\n",
       " 0.33918899297714233,\n",
       " 0.33906012773513794,\n",
       " 0.33894816040992737,\n",
       " 0.33882060647010803,\n",
       " 0.3386971056461334,\n",
       " 0.33857959508895874,\n",
       " 0.33846133947372437,\n",
       " 0.3383334279060364,\n",
       " 0.3382182717323303,\n",
       " 0.3380902409553528,\n",
       " 0.33797869086265564,\n",
       " 0.3378559350967407,\n",
       " 0.33774256706237793,\n",
       " 0.33762502670288086,\n",
       " 0.33750173449516296,\n",
       " 0.3373850882053375,\n",
       " 0.3372618854045868,\n",
       " 0.33714810013771057,\n",
       " 0.3370230197906494,\n",
       " 0.33690309524536133,\n",
       " 0.3367772698402405,\n",
       " 0.3366486728191376,\n",
       " 0.33652886748313904,\n",
       " 0.3364012837409973,\n",
       " 0.3362705409526825,\n",
       " 0.3361490070819855,\n",
       " 0.3360155522823334,\n",
       " 0.3358786106109619,\n",
       " 0.33574968576431274,\n",
       " 0.33561185002326965,\n",
       " 0.335481733083725,\n",
       " 0.33533909916877747,\n",
       " 0.33521437644958496,\n",
       " 0.3350779712200165,\n",
       " 0.33495253324508667,\n",
       " 0.33482226729393005,\n",
       " 0.33469516038894653,\n",
       " 0.3345606327056885,\n",
       " 0.33443018794059753,\n",
       " 0.33429890871047974,\n",
       " 0.3341682553291321,\n",
       " 0.33403486013412476,\n",
       " 0.3339061439037323,\n",
       " 0.3337690234184265,\n",
       " 0.3336363434791565,\n",
       " 0.3335040211677551,\n",
       " 0.3333764970302582,\n",
       " 0.33324670791625977,\n",
       " 0.3331204950809479,\n",
       " 0.3329927921295166,\n",
       " 0.3328683078289032,\n",
       " 0.3327413499355316,\n",
       " 0.33261680603027344,\n",
       " 0.33249565958976746,\n",
       " 0.33237171173095703,\n",
       " 0.332246869802475,\n",
       " 0.3321234881877899,\n",
       " 0.3320003151893616,\n",
       " 0.3318849802017212,\n",
       " 0.33176565170288086,\n",
       " 0.33164602518081665,\n",
       " 0.33153006434440613,\n",
       " 0.3314138650894165,\n",
       " 0.3313000798225403,\n",
       " 0.33118748664855957,\n",
       " 0.3310706317424774,\n",
       " 0.33095431327819824,\n",
       " 0.33083778619766235,\n",
       " 0.33071577548980713,\n",
       " 0.3305974304676056,\n",
       " 0.3304803967475891,\n",
       " 0.3303627371788025,\n",
       " 0.33024871349334717,\n",
       " 0.3301336467266083,\n",
       " 0.33001893758773804,\n",
       " 0.32990533113479614,\n",
       " 0.3297904431819916,\n",
       " 0.329678475856781,\n",
       " 0.329569548368454,\n",
       " 0.3294546902179718,\n",
       " 0.32934364676475525,\n",
       " 0.3292291760444641,\n",
       " 0.3291163742542267,\n",
       " 0.3290032148361206,\n",
       " 0.3288906216621399,\n",
       " 0.3287798762321472,\n",
       " 0.32867318391799927,\n",
       " 0.32856330275535583,\n",
       " 0.3284561038017273,\n",
       " 0.32835128903388977,\n",
       " 0.3282439112663269,\n",
       " 0.328141450881958,\n",
       " 0.3280382752418518,\n",
       " 0.3279343545436859,\n",
       " 0.3278346061706543,\n",
       " 0.3277350068092346,\n",
       " 0.32763010263442993,\n",
       " 0.3275284171104431,\n",
       " 0.3274216949939728,\n",
       " 0.327319473028183,\n",
       " 0.32721540331840515,\n",
       " 0.3271096348762512,\n",
       " 0.3269985318183899,\n",
       " 0.326891154050827,\n",
       " 0.3267815113067627,\n",
       " 0.32667624950408936,\n",
       " 0.3265690207481384,\n",
       " 0.3264659643173218,\n",
       " 0.3263591229915619,\n",
       " 0.3262580633163452,\n",
       " 0.326155424118042,\n",
       " 0.3260512351989746,\n",
       " 0.3259492814540863,\n",
       " 0.32585299015045166,\n",
       " 0.3257473409175873,\n",
       " 0.32564404606819153,\n",
       " 0.3255476653575897,\n",
       " 0.325446218252182,\n",
       " 0.3253419101238251,\n",
       " 0.32524892687797546,\n",
       " 0.32515111565589905,\n",
       " 0.3250502049922943,\n",
       " 0.32495543360710144,\n",
       " 0.3248574435710907,\n",
       " 0.32475435733795166,\n",
       " 0.3246537744998932,\n",
       " 0.3245575726032257,\n",
       " 0.32445767521858215,\n",
       " 0.3243688642978668,\n",
       " 0.32427752017974854,\n",
       " 0.3241836428642273,\n",
       " 0.32408586144447327,\n",
       " 0.32399728894233704,\n",
       " 0.3239048421382904,\n",
       " 0.3238102197647095,\n",
       " 0.3237108588218689,\n",
       " 0.32361435890197754,\n",
       " 0.3235156834125519,\n",
       " 0.323416143655777,\n",
       " 0.3233092427253723,\n",
       " 0.32321593165397644,\n",
       " 0.323117733001709,\n",
       " 0.32301539182662964,\n",
       " 0.32291528582572937,\n",
       " 0.3228078782558441,\n",
       " 0.3227146863937378,\n",
       " 0.32261595129966736,\n",
       " 0.3225196301937103,\n",
       " 0.3224201500415802,\n",
       " 0.32232922315597534,\n",
       " 0.32222938537597656,\n",
       " 0.32213062047958374,\n",
       " 0.322026789188385,\n",
       " 0.3219335079193115,\n",
       " 0.32183459401130676,\n",
       " 0.32174643874168396,\n",
       " 0.3216458261013031,\n",
       " 0.3215544819831848,\n",
       " 0.32145676016807556,\n",
       " 0.3213590085506439,\n",
       " 0.32126688957214355,\n",
       " 0.3211754858493805,\n",
       " 0.32107284665107727,\n",
       " 0.32097548246383667,\n",
       " 0.32087287306785583,\n",
       " 0.32077693939208984,\n",
       " 0.3206765353679657,\n",
       " 0.3205838203430176,\n",
       " 0.32049068808555603,\n",
       " 0.32039734721183777,\n",
       " 0.3203020393848419,\n",
       " 0.3201984763145447,\n",
       " 0.32008489966392517,\n",
       " 0.3199968934059143,\n",
       " 0.3199082016944885,\n",
       " 0.31980735063552856,\n",
       " 0.319713830947876,\n",
       " 0.31961891055107117,\n",
       " 0.3195200264453888,\n",
       " 0.31943023204803467,\n",
       " 0.319341242313385,\n",
       " 0.31925418972969055,\n",
       " 0.3191641867160797,\n",
       " 0.3190828263759613,\n",
       " 0.3189966678619385,\n",
       " 0.3189067244529724,\n",
       " 0.31882017850875854,\n",
       " 0.3187357783317566,\n",
       " 0.3186488747596741,\n",
       " 0.3185585141181946,\n",
       " 0.31847891211509705,\n",
       " 0.3183942139148712,\n",
       " 0.31830713152885437,\n",
       " 0.3182262182235718,\n",
       " 0.31814420223236084,\n",
       " 0.3180631399154663,\n",
       " 0.3179866373538971,\n",
       " 0.31790870428085327,\n",
       " 0.31782564520835876,\n",
       " 0.31775349378585815,\n",
       " 0.31767475605010986,\n",
       " 0.3176032602787018,\n",
       " 0.31752628087997437,\n",
       " 0.3174554109573364,\n",
       " 0.3173831105232239,\n",
       " 0.3173079788684845,\n",
       " 0.3172331750392914,\n",
       " 0.3171587884426117,\n",
       " 0.31708791851997375,\n",
       " 0.3170106112957001,\n",
       " 0.316940575838089,\n",
       " 0.31685495376586914,\n",
       " 0.3167842924594879,\n",
       " 0.3167044520378113,\n",
       " 0.3166166841983795,\n",
       " 0.3165411651134491,\n",
       " 0.3164573907852173,\n",
       " 0.3163723051548004,\n",
       " 0.31629425287246704,\n",
       " 0.3162069320678711,\n",
       " 0.31612688302993774,\n",
       " 0.31604424118995667,\n",
       " 0.3159622550010681,\n",
       " 0.3158823847770691,\n",
       " 0.31580087542533875,\n",
       " 0.3157201111316681,\n",
       " 0.31564271450042725,\n",
       " 0.31555208563804626,\n",
       " 0.3154762089252472,\n",
       " 0.31539276242256165,\n",
       " 0.3153063654899597,\n",
       " 0.3152267336845398,\n",
       " 0.31515514850616455,\n",
       " 0.31506994366645813,\n",
       " 0.3149960935115814,\n",
       " 0.3149266541004181,\n",
       " 0.31485357880592346,\n",
       " 0.31477832794189453,\n",
       " 0.3147076666355133,\n",
       " 0.3146456480026245,\n",
       " 0.31455719470977783,\n",
       " 0.31448906660079956,\n",
       " 0.3144088685512543,\n",
       " 0.3143291175365448,\n",
       " 0.31426483392715454,\n",
       " 0.31418779492378235,\n",
       " 0.31411251425743103,\n",
       " 0.31404733657836914,\n",
       " 0.31397324800491333,\n",
       " 0.31389981508255005,\n",
       " 0.313831090927124,\n",
       " 0.31375646591186523,\n",
       " 0.3136877417564392,\n",
       " 0.3136211633682251,\n",
       " 0.31354832649230957,\n",
       " 0.31348228454589844,\n",
       " 0.3134177029132843,\n",
       " 0.31334295868873596,\n",
       " 0.31328466534614563,\n",
       " 0.31320950388908386,\n",
       " 0.31313320994377136,\n",
       " 0.3130545914173126,\n",
       " 0.3129819631576538,\n",
       " 0.312907338142395,\n",
       " 0.31283628940582275,\n",
       " 0.3127633333206177,\n",
       " 0.31268754601478577,\n",
       " 0.312615305185318,\n",
       " 0.3125406801700592,\n",
       " 0.31247013807296753,\n",
       " 0.3123995065689087,\n",
       " 0.3123314678668976,\n",
       " 0.31225013732910156,\n",
       " 0.31217631697654724,\n",
       " 0.3121092617511749,\n",
       " 0.31203946471214294,\n",
       " 0.31196266412734985,\n",
       " 0.31189730763435364,\n",
       " 0.3118266463279724,\n",
       " 0.311749666929245,\n",
       " 0.31168505549430847,\n",
       " 0.3116188049316406,\n",
       " 0.3115355670452118,\n",
       " 0.31147652864456177,\n",
       " 0.31138986349105835,\n",
       " 0.3113091289997101,\n",
       " 0.31123989820480347,\n",
       " 0.31116482615470886,\n",
       " 0.31108322739601135,\n",
       " 0.31101468205451965,\n",
       " 0.310944527387619,\n",
       " 0.3108716309070587,\n",
       " 0.31079477071762085,\n",
       " 0.31071048974990845,\n",
       " 0.31064745783805847,\n",
       " 0.31057748198509216,\n",
       " 0.3105064332485199,\n",
       " 0.3104308247566223,\n",
       " 0.3103664815425873,\n",
       " 0.3102980852127075,\n",
       " 0.31022870540618896,\n",
       " 0.3101561963558197,\n",
       " 0.310090035200119,\n",
       " 0.31001994013786316,\n",
       " 0.3099496364593506,\n",
       " 0.30987924337387085,\n",
       " 0.30981290340423584,\n",
       " 0.3097451627254486,\n",
       " 0.3096798360347748,\n",
       " 0.3096136152744293,\n",
       " 0.30954670906066895,\n",
       " 0.30948585271835327,\n",
       " 0.3094218671321869,\n",
       " 0.30935826897621155,\n",
       " 0.30929845571517944,\n",
       " 0.3092333674430847,\n",
       " 0.3091764450073242,\n",
       " 0.30911126732826233,\n",
       " 0.3090498447418213,\n",
       " 0.308984637260437,\n",
       " 0.3089224696159363,\n",
       " 0.30886051058769226,\n",
       " 0.3087975084781647,\n",
       " 0.30874189734458923,\n",
       " 0.3086828589439392,\n",
       " 0.3086214065551758,\n",
       " 0.30856722593307495,\n",
       " 0.30850693583488464,\n",
       " 0.30843985080718994,\n",
       " 0.3083805739879608,\n",
       " 0.30831384658813477,\n",
       " 0.30825111269950867,\n",
       " 0.3081854283809662,\n",
       " 0.3081192970275879,\n",
       " 0.3080468475818634,\n",
       " 0.3079768717288971,\n",
       " 0.3079075217247009,\n",
       " 0.3078421652317047,\n",
       " 0.3077736496925354,\n",
       " 0.30771443247795105,\n",
       " 0.30764806270599365,\n",
       " 0.3075841963291168,\n",
       " 0.30752116441726685,\n",
       " 0.3074513077735901,\n",
       " 0.3073909282684326,\n",
       " 0.3073253035545349,\n",
       " 0.30726945400238037,\n",
       " 0.30720800161361694,\n",
       " 0.3071468472480774,\n",
       " 0.3070923089981079,\n",
       " 0.3070315718650818,\n",
       " 0.30697038769721985,\n",
       " 0.3069142997264862,\n",
       " 0.30684852600097656,\n",
       " 0.3067961633205414,\n",
       " 0.306740939617157,\n",
       " 0.3066840171813965,\n",
       " 0.3066270649433136,\n",
       " 0.30656957626342773,\n",
       " 0.3065171539783478,\n",
       " 0.30645573139190674,\n",
       " 0.3064047694206238,\n",
       " 0.30634868144989014,\n",
       " 0.3062909245491028,\n",
       " 0.30623599886894226,\n",
       " 0.3061824440956116,\n",
       " 0.3061257302761078,\n",
       " 0.30606651306152344,\n",
       " 0.3060140311717987,\n",
       " 0.3059559762477875,\n",
       " 0.30590134859085083,\n",
       " 0.30584388971328735,\n",
       " 0.3057945966720581,\n",
       " 0.3057323098182678,\n",
       " 0.3056756258010864,\n",
       " 0.3056086003780365,\n",
       " 0.3055563271045685,\n",
       " 0.30549174547195435,\n",
       " 0.3054264485836029,\n",
       " 0.3053666949272156,\n",
       " 0.3053017556667328,\n",
       " 0.30524054169654846,\n",
       " 0.3051826059818268,\n",
       " 0.305115282535553,\n",
       " 0.3050605058670044,\n",
       " 0.3049960732460022,\n",
       " 0.30494245886802673,\n",
       " 0.30488666892051697,\n",
       " 0.3048241436481476,\n",
       " 0.3047677278518677,\n",
       " 0.30471503734588623,\n",
       " 0.30465516448020935,\n",
       " 0.30460283160209656,\n",
       " 0.3045347034931183,\n",
       " 0.3044791519641876,\n",
       " 0.30442097783088684,\n",
       " 0.30435967445373535,\n",
       " 0.30430489778518677,\n",
       " 0.30423638224601746,\n",
       " 0.3041805922985077,\n",
       " 0.3041185140609741,\n",
       " 0.30405622720718384,\n",
       " 0.3039824664592743,\n",
       " 0.3039381802082062,\n",
       " 0.3038733899593353,\n",
       " 0.3038254678249359,\n",
       " 0.3037678599357605,\n",
       " 0.3037143647670746,\n",
       " 0.30365073680877686,\n",
       " 0.3036021888256073,\n",
       " 0.3035418689250946,\n",
       " 0.30348989367485046,\n",
       " 0.30343347787857056,\n",
       " 0.30337220430374146,\n",
       " 0.3033192753791809,\n",
       " 0.30326545238494873,\n",
       " 0.30320775508880615,\n",
       " 0.3031586706638336,\n",
       " 0.3031022846698761,\n",
       " 0.30304813385009766,\n",
       " 0.30298927426338196,\n",
       " 0.3029266893863678,\n",
       " 0.3028690814971924,\n",
       " 0.3028140664100647,\n",
       " 0.30275824666023254,\n",
       " 0.302701860666275,\n",
       " 0.3026523292064667,\n",
       " 0.3025830388069153,\n",
       " 0.30253589153289795,\n",
       " 0.30247166752815247,\n",
       " 0.3024168312549591,\n",
       " 0.3023568391799927,\n",
       " 0.30231016874313354,\n",
       " 0.3022594749927521,\n",
       " 0.30221033096313477,\n",
       " 0.3021470010280609,\n",
       " 0.3020978271961212,\n",
       " 0.30204033851623535,\n",
       " 0.301984041929245,\n",
       " 0.30193886160850525,\n",
       " 0.3018828332424164,\n",
       " 0.3018384873867035,\n",
       " 0.3017795979976654,\n",
       " 0.301735520362854,\n",
       " 0.3016799986362457,\n",
       " 0.30162808299064636,\n",
       " 0.30157408118247986,\n",
       " 0.3015318810939789,\n",
       " 0.30147233605384827,\n",
       " 0.30143100023269653,\n",
       " 0.3013748526573181,\n",
       " 0.3013334274291992,\n",
       " 0.3012830913066864,\n",
       " 0.30122894048690796,\n",
       " 0.30118605494499207,\n",
       " 0.3011322617530823,\n",
       " 0.3010871112346649,\n",
       " 0.30103692412376404,\n",
       " 0.30098822712898254,\n",
       " 0.3009411096572876,\n",
       " 0.30089741945266724,\n",
       " 0.30084213614463806,\n",
       " 0.30080273747444153,\n",
       " 0.3007492125034332,\n",
       " 0.3007059395313263,\n",
       " 0.300658643245697,\n",
       " 0.30061087012290955,\n",
       " 0.3005688786506653,\n",
       " 0.3005152642726898,\n",
       " 0.3004814386367798,\n",
       " 0.3004245460033417,\n",
       " 0.30039966106414795,\n",
       " 0.30033791065216064,\n",
       " 0.3003133535385132,\n",
       " 0.3002503514289856,\n",
       " 0.30022478103637695,\n",
       " 0.30016693472862244,\n",
       " 0.3001311421394348,\n",
       " 0.3000876009464264,\n",
       " 0.300044447183609,\n",
       " 0.30001136660575867,\n",
       " 0.2999623715877533,\n",
       " 0.2999350130558014,\n",
       " 0.29988792538642883,\n",
       " 0.29984939098358154,\n",
       " 0.29981568455696106,\n",
       " 0.2997702658176422,\n",
       " 0.2997441589832306,\n",
       " 0.2996891140937805,\n",
       " 0.2996659278869629,\n",
       " 0.2996152937412262,\n",
       " 0.2995810806751251,\n",
       " 0.2995445132255554,\n",
       " 0.29949870705604553,\n",
       " 0.2994703948497772,\n",
       " 0.2994142174720764,\n",
       " 0.29938676953315735,\n",
       " 0.29934078454971313,\n",
       " 0.29930078983306885,\n",
       " 0.2992662489414215,\n",
       " 0.2992208003997803,\n",
       " 0.29919102787971497,\n",
       " 0.29914239048957825,\n",
       " 0.2991124987602234,\n",
       " 0.2990666627883911,\n",
       " 0.29903146624565125,\n",
       " 0.29899951815605164,\n",
       " 0.2989535331726074,\n",
       " 0.2989264130592346,\n",
       " 0.2988821566104889,\n",
       " 0.2988514304161072,\n",
       " 0.2988119423389435,\n",
       " 0.29877176880836487,\n",
       " 0.2987363040447235,\n",
       " 0.2986939549446106,\n",
       " 0.29866138100624084,\n",
       " 0.29861560463905334,\n",
       " 0.29859083890914917,\n",
       " 0.2985471189022064,\n",
       " 0.2985125780105591,\n",
       " 0.298484742641449,\n",
       " 0.29844334721565247,\n",
       " 0.29841741919517517,\n",
       " 0.2983749806880951,\n",
       " 0.2983483672142029,\n",
       " 0.29830601811408997,\n",
       " 0.29827845096588135,\n",
       " 0.298243910074234,\n",
       " 0.29820582270622253,\n",
       " 0.29817667603492737,\n",
       " 0.2981383800506592,\n",
       " 0.2981155216693878,\n",
       " 0.2980746030807495,\n",
       " 0.29804524779319763,\n",
       " 0.2980120778083801,\n",
       " 0.29798221588134766,\n",
       " 0.2979426383972168,\n",
       " 0.29791131615638733,\n",
       " 0.2978796660900116,\n",
       " 0.29784220457077026,\n",
       " 0.2978135943412781,\n",
       " 0.2977817952632904,\n",
       " 0.29774755239486694,\n",
       " 0.29772111773490906,\n",
       " 0.2976829409599304,\n",
       " 0.2976572513580322,\n",
       " 0.29761558771133423,\n",
       " 0.2975948750972748,\n",
       " 0.2975587546825409,\n",
       " 0.29752564430236816,\n",
       " 0.29750198125839233,\n",
       " 0.2974611520767212,\n",
       " 0.2974378168582916,\n",
       " 0.2974063754081726,\n",
       " 0.2973719835281372,\n",
       " 0.2973492443561554,\n",
       " 0.2973099648952484,\n",
       " 0.29729124903678894,\n",
       " 0.29725292325019836,\n",
       " 0.2972201704978943,\n",
       " 0.29720214009284973,\n",
       " 0.2971598207950592,\n",
       " 0.2971397042274475,\n",
       " 0.29710516333580017,\n",
       " 0.2970743477344513,\n",
       " 0.2970457375049591,\n",
       " 0.29701241850852966,\n",
       " 0.2969909608364105,\n",
       " 0.29695382714271545,\n",
       " 0.2969368100166321,\n",
       " 0.2968995273113251,\n",
       " 0.29688188433647156,\n",
       " 0.29683718085289,\n",
       " 0.2968243956565857,\n",
       " 0.2967880666255951,\n",
       " 0.296766072511673,\n",
       " 0.2967413365840912,\n",
       " 0.2967034578323364,\n",
       " 0.2966863214969635,\n",
       " 0.2966461479663849,\n",
       " 0.2966350317001343,\n",
       " 0.29659268260002136,\n",
       " 0.2965720295906067,\n",
       " 0.29653459787368774,\n",
       " 0.2965085506439209,\n",
       " 0.29648226499557495,\n",
       " 0.2964514195919037,\n",
       " 0.2964266836643219,\n",
       " 0.29640594124794006,\n",
       " 0.29636532068252563,\n",
       " 0.2963494658470154,\n",
       " 0.2963123917579651,\n",
       " 0.2963002622127533,\n",
       " 0.2962628901004791,\n",
       " 0.2962436079978943,\n",
       " 0.29621386528015137,\n",
       " 0.29618969559669495,\n",
       " 0.29616615176200867,\n",
       " 0.29613929986953735,\n",
       " 0.29610908031463623,\n",
       " 0.2960847318172455,\n",
       " 0.29605600237846375,\n",
       " 0.29603487253189087,\n",
       " 0.2960062026977539,\n",
       " 0.2959790527820587,\n",
       " 0.29595494270324707,\n",
       " 0.29593023657798767,\n",
       " 0.295902818441391,\n",
       " 0.2958754003047943,\n",
       " 0.2958526909351349,\n",
       " 0.29582008719444275,\n",
       " 0.2957996129989624,\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history[\"loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(history.history)\n",
    "df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - loss: 0.3081\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.32077696919441223"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)\n",
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.8875113 ],\n",
       "       [1.509506  ],\n",
       "       [0.40314513]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_nueva = X_test[:3]\n",
    "y_nueva = model.predict(X_nueva)\n",
    "y_nueva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model/modelito.keras\")\n",
    "# keras.models.load_model(\"model/modelito.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3000 - val_loss: 0.3084\n",
      "Epoch 2/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3000 - val_loss: 0.3084\n",
      "Epoch 3/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2999 - val_loss: 0.3084\n",
      "Epoch 4/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2999 - val_loss: 0.3084\n",
      "Epoch 5/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2999 - val_loss: 0.3084\n",
      "Epoch 6/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2999 - val_loss: 0.3084\n",
      "Epoch 7/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2999 - val_loss: 0.3083\n",
      "Epoch 8/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2998 - val_loss: 0.3083\n",
      "Epoch 9/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2998 - val_loss: 0.3083\n",
      "Epoch 10/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2998 - val_loss: 0.3083\n",
      "Epoch 11/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2998 - val_loss: 0.3083\n",
      "Epoch 12/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2997 - val_loss: 0.3083\n",
      "Epoch 13/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2997 - val_loss: 0.3083\n",
      "Epoch 14/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2997 - val_loss: 0.3083\n",
      "Epoch 15/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2997 - val_loss: 0.3083\n",
      "Epoch 16/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2996 - val_loss: 0.3083\n",
      "Epoch 17/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2996 - val_loss: 0.3083\n",
      "Epoch 18/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2996 - val_loss: 0.3082\n",
      "Epoch 19/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2996 - val_loss: 0.3082\n",
      "Epoch 20/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2996 - val_loss: 0.3082\n"
     ]
    }
   ],
   "source": [
    "#TensorBoard\n",
    "root_logdir = os.path.join(\".\", \"archives/logs\")\n",
    "#root_logdir = \"./my_logs\"\n",
    "\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"model/my_keras_model.keras\", save_best_only=True)\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(root_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_val, y_val),\n",
    "                    callbacks=[checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 22068), started 0:37:19 ago. (Use '!kill 22068' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-71e2b953ff04df99\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-71e2b953ff04df99\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "tensorboard --logdir = ./my_logs --port= 6006\n",
    "\"\"\"\n",
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
